{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GeneralModel as gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df, target_var, cont_vars=[], cat_vars=[]):\n",
    "    total_vars = cont_vars + cat_vars + [target_var]\n",
    "    model_df = df[total_vars]\n",
    "    cleaned_df = model_df.dropna(subset=total_vars)\n",
    "\n",
    "    # turns categorical variables into dummy variables\n",
    "    for var in cat_vars:\n",
    "        temp_dummy = pd.get_dummies(cleaned_df[var], drop_first=True)\n",
    "        cleaned_df = pd.concat([cleaned_df.drop([var], axis=1), temp_dummy], axis=1)\n",
    "\n",
    "    # normalize the data\n",
    "    for var in cont_vars:\n",
    "        cleaned_df[var] = preprocessing.scale(cleaned_df[var])\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_split = pd.read_csv('../../DataPlus/va_split.csv')\n",
    "dvd_split = pd.read_csv('../../DataPlus/dvd_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars=['age']\n",
    "cat_vars=['edu_binary', 'marry_binary', 'white_binary', 'Advice1', 'gleason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = prepare_df(va_split, 'txgot_binary', cont_vars, cat_vars)\n",
    "dvd = prepare_df(va_split, 'txgot_binary', cont_vars, cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbclassify(df, model, trainCV=True, target='txgot_binary', folds=5, iterations=5):\n",
    "    \n",
    "    feat_vars = [var for var in list(df.columns) if var != target]\n",
    "    X = df[feat_vars].values\n",
    "    y = df[target].values\n",
    "    \n",
    "    avg_pos_prec = 0\n",
    "    avg_pos_rec = 0\n",
    "    avg_neg_prec = 0\n",
    "    avg_neg_rec = 0\n",
    "    avg_auc = 0\n",
    "    \n",
    "    rskf = RepeatedStratifiedKFold(n_splits=folds, n_repeats=iterations)\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        auc, (tn, fp, fn, tp) = xgbmodel(model, X_train, X_test, y_train, y_test, trainCV=True)\n",
    "        avg_auc += auc\n",
    "        \n",
    "        avg_pos_prec += tp / (tp + fp)\n",
    "        avg_pos_rec += tp / (tp + fn)\n",
    "        avg_neg_prec += tn / (tn + fn)\n",
    "        avg_neg_rec += tn / (tn + fp)\n",
    "        \n",
    "    avg_auc /= (folds*iterations)\n",
    "    avg_pos_prec /= (folds * iterations)\n",
    "    avg_pos_rec /= (folds * iterations)\n",
    "    avg_neg_prec /= (folds * iterations)\n",
    "    avg_neg_rec /= (folds * iterations)\n",
    "    \n",
    "    print('Average Metrics:')\n",
    "    print('Positive Class Precision: {}'.format(round(avg_pos_prec, 3)))\n",
    "    print('Positive Class Recall: {}'.format(round(avg_pos_rec, 3)))\n",
    "    print('Negative Class Precision: {}'.format(round(avg_neg_prec, 3)))\n",
    "    print('Negative Class Recall: {}'.format(round(avg_neg_rec, 3)))\n",
    "    \n",
    "    print()\n",
    "    print('Feature Importance:')\n",
    "    sorted_idx = np.argsort(model.feature_importances_)[::-1]\n",
    "    for index in sorted_idx:\n",
    "        print([feat_vars[index], model.feature_importances_[index]])\n",
    "        \n",
    "    return avg_auc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbmodel(model, X_train, X_test, y_train, y_test, trainCV=True):\n",
    "    my_model = model\n",
    "    my_model.fit(X_train, y_train)\n",
    "    pred = my_model.predict(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, pred, pos_label=1)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    \n",
    "    metrics = confusion_matrix(y_test, pred).ravel()\n",
    "\n",
    "    return auc_score, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics:\n",
      "Positive Class Precision: 0.752\n",
      "Positive Class Recall: 0.767\n",
      "Negative Class Precision: 0.803\n",
      "Negative Class Recall: 0.783\n",
      "\n",
      "Feature Importance:\n",
      "['age', 0.44752476]\n",
      "[7.0, 0.11485148]\n",
      "['S', 0.10891089]\n",
      "['Not Married', 0.104950495]\n",
      "['R', 0.06336634]\n",
      "['SR', 0.05940594]\n",
      "['No College Degree', 0.043564357]\n",
      "['White', 0.02970297]\n",
      "['AS', 0.01980198]\n",
      "['ASR', 0.007920792]\n",
      "['AR', 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7750446224256292"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclassify(va, xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics:\n",
      "Positive Class Precision: 0.76\n",
      "Positive Class Recall: 0.779\n",
      "Negative Class Precision: 0.815\n",
      "Negative Class Recall: 0.789\n",
      "\n",
      "Feature Importance:\n",
      "['age', 0.4061372]\n",
      "[7.0, 0.10469314]\n",
      "['Not Married', 0.08844765]\n",
      "['SR', 0.08122744]\n",
      "['S', 0.077617325]\n",
      "['R', 0.06859206]\n",
      "['White', 0.066787004]\n",
      "['No College Degree', 0.04693141]\n",
      "['ASR', 0.0433213]\n",
      "['AS', 0.016245488]\n",
      "['AR', 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7843745232646833"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclassify(dvd, xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataPlus",
   "language": "python",
   "name": "dataplus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GeneralModel as gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_split = pd.read_csv('../../DataPlus/va_split.csv')\n",
    "dvd_split = pd.read_csv('../../DataPlus/dvd_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Data Points: 216\n",
      "# of Data Points: 176\n"
     ]
    }
   ],
   "source": [
    "va_df = gm.prepare_df(va_split, ['age'], ['gleason'], 'txgot_binary')\n",
    "dvd_df = gm.prepare_df(dvd_split, ['age'], ['gleason'], 'txgot_binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_xg = XGBClassifier()\n",
    "dvd_xg = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_X = va_df.drop(['txgot_binary'], axis=1).values\n",
    "va_y = va_df['txgot_binary'].values\n",
    "dvd_X = dvd_df.drop(['txgot_binary'], axis=1).values\n",
    "dvd_y = dvd_df['txgot_binary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_va, test_X_va, train_y_va, test_y_va = train_test_split(va_X, va_y, test_size=0.6)\n",
    "train_X_dvd, test_X_dvd, train_y_dvd, test_y_dvd = train_test_split(dvd_X, dvd_y, test_size=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_xg.fit(train_X_va, train_y_va, verbose=False)\n",
    "dvd_xg.fit(train_X_dvd, train_y_dvd, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_va = va_xg.predict(test_X_va)\n",
    "predictions_dvd = dvd_xg.predict(test_X_dvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VA confusion matrix:\n",
      "[[49 15]\n",
      " [20 46]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.77      0.74        64\n",
      "        1.0       0.75      0.70      0.72        66\n",
      "\n",
      "avg / total       0.73      0.73      0.73       130\n",
      "\n",
      "DVD confusion matrix:\n",
      "[[62 10]\n",
      " [21 13]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.75      0.86      0.80        72\n",
      "        1.0       0.57      0.38      0.46        34\n",
      "\n",
      "avg / total       0.69      0.71      0.69       106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"VA confusion matrix:\")\n",
    "print(confusion_matrix(predictions_va, test_y_va))\n",
    "print(classification_report(predictions_va, test_y_va))\n",
    "print(\"DVD confusion matrix:\")\n",
    "print(confusion_matrix(predictions_dvd, test_y_dvd))\n",
    "print(classification_report(predictions_dvd, test_y_dvd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Around with # of Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to determin the best fit n_estimators.\n",
    "def xgbr(n_estimator,X_train,X_test,y_train,y_test):\n",
    "    my_model = XGBClassifier(n_estimators=n_estimator)\n",
    "    my_model.fit(X_train, y_train)\n",
    "    pred = my_model.predict(X_test)\n",
    "    return str(mean_absolute_error(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VA Evaluation:\n",
      "Number of estimators: 100  \t\t Mean Absolute Error:  0.2692307692307692\n",
      "VA Evaluation:\n",
      "Number of estimators: 500  \t\t Mean Absolute Error:  0.2923076923076923\n",
      "VA Evaluation:\n",
      "Number of estimators: 1000  \t\t Mean Absolute Error:  0.2923076923076923\n",
      "VA Evaluation:\n",
      "Number of estimators: 1500  \t\t Mean Absolute Error:  0.2923076923076923\n",
      "VA Evaluation:\n",
      "Number of estimators: 2000  \t\t Mean Absolute Error:  0.2923076923076923\n",
      "VA Evaluation:\n",
      "Number of estimators: 2500  \t\t Mean Absolute Error:  0.2923076923076923\n",
      "\n",
      "VA Evaluation:\n",
      "Number of estimators: 100  \t\t Mean Absolute Error:  0.29245283018867924\n",
      "VA Evaluation:\n",
      "Number of estimators: 500  \t\t Mean Absolute Error:  0.2830188679245283\n",
      "VA Evaluation:\n",
      "Number of estimators: 1000  \t\t Mean Absolute Error:  0.2830188679245283\n",
      "VA Evaluation:\n",
      "Number of estimators: 1500  \t\t Mean Absolute Error:  0.2830188679245283\n",
      "VA Evaluation:\n",
      "Number of estimators: 2000  \t\t Mean Absolute Error:  0.2830188679245283\n",
      "VA Evaluation:\n",
      "Number of estimators: 2500  \t\t Mean Absolute Error:  0.2830188679245283\n"
     ]
    }
   ],
   "source": [
    "for estimators in [100,500,1000,1500,2000,2500]:\n",
    "    mae=xgbr(estimators,train_X_va,test_X_va,train_y_va,test_y_va)\n",
    "    print(\"VA Evaluation:\")\n",
    "    print(\"Number of estimators: {}  \\t\\t Mean Absolute Error:  {}\".format(estimators, mae))\n",
    "print()\n",
    "for estimators in [100,500,1000,1500,2000,2500]:\n",
    "    mae=xgbr(estimators,train_X_dvd,test_X_dvd,train_y_dvd,test_y_dvd)\n",
    "    print(\"VA Evaluation:\")\n",
    "    print(\"Number of estimators: {}  \\t\\t Mean Absolute Error:  {}\".format(estimators, mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error doesn't change much after 500 estimators, probably even less. Then again, we have a really small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VA Evaluation:\n",
      "Number of estimators: 10  \t\t Mean Absolute Error:  0.2692307692307692\n",
      "VA Evaluation:\n",
      "Number of estimators: 20  \t\t Mean Absolute Error:  0.2692307692307692\n",
      "VA Evaluation:\n",
      "Number of estimators: 30  \t\t Mean Absolute Error:  0.2692307692307692\n",
      "VA Evaluation:\n",
      "Number of estimators: 40  \t\t Mean Absolute Error:  0.2692307692307692\n",
      "VA Evaluation:\n",
      "Number of estimators: 50  \t\t Mean Absolute Error:  0.2692307692307692\n",
      "\n",
      "VA Evaluation:\n",
      "Number of estimators: 10  \t\t Mean Absolute Error:  0.25471698113207547\n",
      "VA Evaluation:\n",
      "Number of estimators: 20  \t\t Mean Absolute Error:  0.25471698113207547\n",
      "VA Evaluation:\n",
      "Number of estimators: 30  \t\t Mean Absolute Error:  0.2641509433962264\n",
      "VA Evaluation:\n",
      "Number of estimators: 40  \t\t Mean Absolute Error:  0.29245283018867924\n",
      "VA Evaluation:\n",
      "Number of estimators: 50  \t\t Mean Absolute Error:  0.29245283018867924\n"
     ]
    }
   ],
   "source": [
    "for estimators in [10, 20, 30, 40, 50]:\n",
    "    mae=xgbr(estimators,train_X_va,test_X_va,train_y_va,test_y_va)\n",
    "    print(\"VA Evaluation:\")\n",
    "    print(\"Number of estimators: {}  \\t\\t Mean Absolute Error:  {}\".format(estimators, mae))\n",
    "print()\n",
    "for estimators in [10, 20, 30, 40, 50]:\n",
    "    mae=xgbr(estimators,train_X_dvd,test_X_dvd,train_y_dvd,test_y_dvd)\n",
    "    print(\"VA Evaluation:\")\n",
    "    print(\"Number of estimators: {}  \\t\\t Mean Absolute Error:  {}\".format(estimators, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VA Evaluation:\n",
      "Number of estimators: 5  \t\t Mean Absolute Error:  0.41531904202241166\n",
      "VA Evaluation:\n",
      "Number of estimators: 10  \t\t Mean Absolute Error:  0.36579068371882806\n",
      "VA Evaluation:\n",
      "Number of estimators: 15  \t\t Mean Absolute Error:  0.3388300590790235\n",
      "VA Evaluation:\n",
      "Number of estimators: 20  \t\t Mean Absolute Error:  0.3252392450204262\n",
      "VA Evaluation:\n",
      "Number of estimators: 25  \t\t Mean Absolute Error:  0.3214148065218559\n",
      "\n",
      "VA Evaluation:\n",
      "Number of estimators: 5  \t\t Mean Absolute Error:  0.4217099744193959\n",
      "VA Evaluation:\n",
      "Number of estimators: 10  \t\t Mean Absolute Error:  0.37527544627774434\n",
      "VA Evaluation:\n",
      "Number of estimators: 15  \t\t Mean Absolute Error:  0.3450969342353209\n",
      "VA Evaluation:\n",
      "Number of estimators: 20  \t\t Mean Absolute Error:  0.33119347410381966\n",
      "VA Evaluation:\n",
      "Number of estimators: 25  \t\t Mean Absolute Error:  0.3261720993608799\n"
     ]
    }
   ],
   "source": [
    "for estimators in [5, 10, 15, 20, 25]:\n",
    "    mae=xgbr(estimators,train_X_va,test_X_va,train_y_va,test_y_va)\n",
    "    print(\"VA Evaluation:\")\n",
    "    print(\"Number of estimators: {}  \\t\\t Mean Absolute Error:  {}\".format(estimators, mae))\n",
    "print()\n",
    "for estimators in [5, 10, 15, 20, 25]:\n",
    "    mae=xgbr(estimators,train_X_dvd,test_X_dvd,train_y_dvd,test_y_dvd)\n",
    "    print(\"VA Evaluation:\")\n",
    "    print(\"Number of estimators: {}  \\t\\t Mean Absolute Error:  {}\".format(estimators, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VA Evaluation:\n",
      "Number of estimators: 20  \t\t Mean Absolute Error:  0.2692307692307692\n",
      "VA Evaluation:\n",
      "Number of estimators: 25  \t\t Mean Absolute Error:  0.2692307692307692\n",
      "VA Evaluation:\n",
      "Number of estimators: 30  \t\t Mean Absolute Error:  0.2692307692307692\n",
      "VA Evaluation:\n",
      "Number of estimators: 35  \t\t Mean Absolute Error:  0.2692307692307692\n",
      "VA Evaluation:\n",
      "Number of estimators: 40  \t\t Mean Absolute Error:  0.2692307692307692\n",
      "\n",
      "VA Evaluation:\n",
      "Number of estimators: 20  \t\t Mean Absolute Error:  0.25471698113207547\n",
      "VA Evaluation:\n",
      "Number of estimators: 25  \t\t Mean Absolute Error:  0.25471698113207547\n",
      "VA Evaluation:\n",
      "Number of estimators: 30  \t\t Mean Absolute Error:  0.2641509433962264\n",
      "VA Evaluation:\n",
      "Number of estimators: 35  \t\t Mean Absolute Error:  0.2641509433962264\n",
      "VA Evaluation:\n",
      "Number of estimators: 40  \t\t Mean Absolute Error:  0.29245283018867924\n"
     ]
    }
   ],
   "source": [
    "for estimators in [20, 25, 30, 35, 40]:\n",
    "    mae=xgbr(estimators,train_X_va,test_X_va,train_y_va,test_y_va)\n",
    "    print(\"VA Evaluation:\")\n",
    "    print(\"Number of estimators: {}  \\t\\t Mean Absolute Error:  {}\".format(estimators, mae))\n",
    "print()\n",
    "for estimators in [20, 25, 30, 35, 40]:\n",
    "    mae=xgbr(estimators,train_X_dvd,test_X_dvd,train_y_dvd,test_y_dvd)\n",
    "    print(\"VA Evaluation:\")\n",
    "    print(\"Number of estimators: {}  \\t\\t Mean Absolute Error:  {}\".format(estimators, mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that between 35 and 40 is the sweet spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to determin the best fit n_estimators.\n",
    "def xgbr(n_estimator,X_train,X_test,y_train,y_test):\n",
    "    my_model = XGBClassifier(n_estimators=n_estimator)\n",
    "    my_model.fit(X_train, y_train)\n",
    "    pred = my_model.predict(X_test)\n",
    "    print(\"Results:\")\n",
    "    print(confusion_matrix(pred, y_test))\n",
    "    print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "[[49 15]\n",
      " [20 46]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.77      0.74        64\n",
      "        1.0       0.75      0.70      0.72        66\n",
      "\n",
      "avg / total       0.73      0.73      0.73       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbr(35, train_X_va, test_X_va, train_y_va, test_y_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "[[65 10]\n",
      " [18 13]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.78      0.87      0.82        75\n",
      "        1.0       0.57      0.42      0.48        31\n",
      "\n",
      "avg / total       0.72      0.74      0.72       106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbr(35, train_X_dvd, test_X_dvd, train_y_dvd, test_y_dvd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on One Dataset -> Test on Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "[[84 11]\n",
      " [45 36]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.65      0.88      0.75        95\n",
      "        1.0       0.77      0.44      0.56        81\n",
      "\n",
      "avg / total       0.70      0.68      0.66       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbr(35, va_X, dvd_X, va_y, dvd_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "[[101  49]\n",
      " [ 17  49]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.67      0.75       150\n",
      "        1.0       0.50      0.74      0.60        66\n",
      "\n",
      "avg / total       0.75      0.69      0.71       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbr(35, dvd_X, va_X, dvd_y, va_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x000002A130D37C18>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\grant\\Anaconda3\\envs\\dataplus\\lib\\site-packages\\xgboost\\core.py\", line 366, in __del__\n",
      "    if self.handle is not None:\n",
      "AttributeError: 'DMatrix' object has no attribute 'handle'\n"
     ]
    }
   ],
   "source": [
    "def modelfit(alg, dtrain, target, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\") % metrics.accuracy_score(dtrain[target].values, dtrain_predictions)\n",
    "    print(\"AUC Score (Train): %f\") % metrics.roc_auc_score(dtrain[target], dtrain_predprob)\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['age', 'gleason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'txgot_binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "b'[12:11:12] d:\\\\build\\\\xgboost\\\\xgboost-0.71.git\\\\src\\\\objective\\\\regression_obj.cc:103: Check failed: Loss::CheckLabel(y) label must be in [0,1] for logistic regression'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-5701f19f49c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mva_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-89-f8dcd9ae3ce2>\u001b[0m in \u001b[0;36mmodelfit\u001b[1;34m(alg, dtrain, target, predictors, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mxgtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n\u001b[1;32m----> 7\u001b[1;33m             metrics='auc', early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcvresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataplus\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[0;32m    404\u001b[0m                            evaluation_result_list=None))\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataplus\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataplus\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m--> 894\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m    895\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataplus\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: b'[12:11:12] d:\\\\build\\\\xgboost\\\\xgboost-0.71.git\\\\src\\\\objective\\\\regression_obj.cc:103: Check failed: Loss::CheckLabel(y) label must be in [0,1] for logistic regression'"
     ]
    }
   ],
   "source": [
    "modelfit(xgb1, va_split, target_col, train_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataPlus",
   "language": "python",
   "name": "dataplus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

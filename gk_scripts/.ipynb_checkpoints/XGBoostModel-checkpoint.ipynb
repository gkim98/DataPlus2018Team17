{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GeneralModel as gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df, target_var, cont_vars=[], cat_vars=[]):\n",
    "    total_vars = cont_vars + cat_vars + [target_var]\n",
    "    model_df = df[total_vars]\n",
    "    cleaned_df = model_df.dropna(subset=total_vars)\n",
    "\n",
    "    # turns categorical variables into dummy variables\n",
    "    for var in cat_vars:\n",
    "        temp_dummy = pd.get_dummies(cleaned_df[var], drop_first=True)\n",
    "        cleaned_df = pd.concat([cleaned_df.drop([var], axis=1), temp_dummy], axis=1)\n",
    "\n",
    "    # normalize the data\n",
    "    for var in cont_vars:\n",
    "        cleaned_df[var] = preprocessing.scale(cleaned_df[var])\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_split = pd.read_csv('../../DataPlus/va_split.csv')\n",
    "dvd_split = pd.read_csv('../../DataPlus/dvd_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars=['age']\n",
    "cat_vars=['edu_binary', 'marry_binary', 'white_binary', 'Advice1', 'gleason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = prepare_df(va_split, 'txgot_binary', cont_vars, cat_vars)\n",
    "dvd = prepare_df(va_split, 'txgot_binary', cont_vars, cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbclassify(df, model, trainCV=True, target='txgot_binary', folds=5, iterations=5):\n",
    "    \n",
    "    feat_vars = [var for var in list(df.columns) if var != target]\n",
    "    X = df[feat_vars].values\n",
    "    y = df[target].values\n",
    "    \n",
    "    avg_pos_prec = 0\n",
    "    avg_pos_rec = 0\n",
    "    avg_neg_prec = 0\n",
    "    avg_neg_rec = 0\n",
    "    avg_auc = 0\n",
    "    \n",
    "    rskf = RepeatedStratifiedKFold(n_splits=folds, n_repeats=iterations)\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        auc, (tn, fp, fn, tp) = xgbmodel(model, X_train, X_test, y_train, y_test, trainCV=True)\n",
    "        avg_auc += auc\n",
    "        \n",
    "        avg_pos_prec += tp / (tp + fp)\n",
    "        avg_pos_rec += tp / (tp + fn)\n",
    "        avg_neg_prec += tn / (tn + fn)\n",
    "        avg_neg_rec += tn / (tn + fp)\n",
    "        \n",
    "    avg_auc /= (folds*iterations)\n",
    "    avg_pos_prec /= (folds * iterations)\n",
    "    avg_pos_rec /= (folds * iterations)\n",
    "    avg_neg_prec /= (folds * iterations)\n",
    "    avg_neg_rec /= (folds * iterations)\n",
    "    \n",
    "    print('Average Metrics:')\n",
    "    print('Positive Class Precision: {}'.format(round(avg_pos_prec, 3)))\n",
    "    print('Positive Class Recall: {}'.format(round(avg_pos_rec, 3)))\n",
    "    print('Negative Class Precision: {}'.format(round(avg_neg_prec, 3)))\n",
    "    print('Negative Class Recall: {}'.format(round(avg_neg_rec, 3)))\n",
    "    \n",
    "    print()\n",
    "    print('Feature Importance:')\n",
    "    sorted_idx = np.argsort(model.feature_importances_)[::-1]\n",
    "    for index in sorted_idx:\n",
    "        print([train.columns[index], model.feature_importances_[index]])\n",
    "        \n",
    "    return avg_auc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbmodel(model, X_train, X_test, y_train, y_test, trainCV=True):\n",
    "    my_model = model\n",
    "    my_model.fit(X_train, y_train)\n",
    "    pred = my_model.predict(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, pred, pos_label=1)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    \n",
    "    metrics = confusion_matrix(y_test, pred).ravel()\n",
    "\n",
    "    return auc_score, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics:\n",
      "Positive Class Precision: 0.751\n",
      "Positive Class Recall: 0.789\n",
      "Negative Class Precision: 0.818\n",
      "Negative Class Recall: 0.772\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'plot_importance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-8fade6d34401>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgbclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mva\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-74-05336374cdf3>\u001b[0m in \u001b[0;36mxgbclassify\u001b[1;34m(df, model, trainCV, target, folds, iterations)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mavg_auc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'plot_importance'"
     ]
    }
   ],
   "source": [
    "xgbclassify(va, xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics:\n",
      "Positive Class Precision: 0.758\n",
      "Positive Class Recall: 0.778\n",
      "Negative Class Precision: 0.814\n",
      "Negative Class Recall: 0.788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7832917620137301"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclassify(dvd, xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataPlus",
   "language": "python",
   "name": "dataplus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

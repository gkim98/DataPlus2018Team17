{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from ipywidgets import IntProgress\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# silences package warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df, target_var, cont_vars=[], cat_vars=[]):\n",
    "    total_vars = cont_vars + cat_vars + [target_var]\n",
    "    model_df = df[total_vars]\n",
    "    cleaned_df = model_df.dropna(subset=total_vars)\n",
    "\n",
    "    # turns categorical variables into dummy variables\n",
    "    for var in cat_vars:\n",
    "        temp_dummy = pd.get_dummies(cleaned_df[var], drop_first=True)\n",
    "        cleaned_df = pd.concat([cleaned_df.drop([var], axis=1), temp_dummy], axis=1)\n",
    "\n",
    "    # normalize the data\n",
    "    for var in cont_vars:\n",
    "        cleaned_df[var] = preprocessing.scale(cleaned_df[var])\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbclassify(df, model, params=None, trainCV='none', target='txgot_binary', folds=5, iterations=100, print_id=1):\n",
    "    \n",
    "    feat_vars = [var for var in list(df.columns) if var != target]\n",
    "    X = df[feat_vars].values\n",
    "    y = df[target].values\n",
    "    \n",
    "    if trainCV=='grid':\n",
    "        param_bins = {key: {i:0 for i in params[key]} for key in params.keys()}\n",
    "    \n",
    "    avg_train_auc = 0\n",
    "    avg_test_auc = 0\n",
    "    avg_train_acc = 0\n",
    "    avg_test_acc = 0\n",
    "    \n",
    "    rskf = RepeatedStratifiedKFold(n_splits=folds, n_repeats=iterations)\n",
    "    for train_index, test_index in tqdm(rskf.split(X, y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        train_auc, test_auc, train_acc, test_acc, best_params = xgbmodel(model, params, \n",
    "                                                                         X_train, X_test, \n",
    "                                                                         y_train, y_test, \n",
    "                                                                         trainCV, print_id)\n",
    "        \n",
    "        if trainCV=='grid':\n",
    "            for key, value in best_params.items():\n",
    "                param_bins[key][value] += 1\n",
    "        \n",
    "        avg_train_auc += train_auc\n",
    "        avg_test_auc += test_auc\n",
    "        avg_train_acc += train_acc\n",
    "        avg_test_acc += test_acc\n",
    "        \n",
    "    avg_train_auc /= (folds * iterations)\n",
    "    avg_test_auc /= (folds * iterations)\n",
    "    avg_train_acc /= (folds * iterations)\n",
    "    avg_test_acc /= (folds * iterations)\n",
    "    \n",
    "    print('Train vs. Test')\n",
    "    print('Training AUC: {}'.format(round(avg_train_auc, 3)))\n",
    "    print('Testing AUC: {}'.format(round(avg_test_auc, 3)))\n",
    "    print()\n",
    "    print('Training Accuracy: {}'.format(round(avg_train_acc, 3)))\n",
    "    print('Testing Accuracy: {}'.format(round(avg_test_acc, 3)))\n",
    "    \n",
    "    if trainCV=='grid':\n",
    "        print()\n",
    "        for key, value in param_bins.items():\n",
    "            print('{}: {}'.format(key, value))\n",
    "    \n",
    "    print()\n",
    "    print('Feature Importance:')\n",
    "    if not (trainCV is 'random' or trainCV is 'grid'):\n",
    "        sorted_idx = np.argsort(model.feature_importances_)[::-1]\n",
    "        for index in sorted_idx:\n",
    "            print([feat_vars[index], model.feature_importances_[index]])\n",
    "        \n",
    "    return avg_train_auc, avg_test_auc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbmodel(model, params, X_train, X_test, y_train, y_test, trainCV, print_id):\n",
    "    if trainCV is 'random':\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle = True, random_state=print_id)\n",
    "        \n",
    "        X = np.concatenate((X_train, X_test), axis=0)\n",
    "        Y = np.concatenate((y_train, y_test), axis=0)\n",
    "        \n",
    "        my_model = RandomizedSearchCV(model, param_distributions=params, n_iter=5, \n",
    "                           scoring='roc_auc', n_jobs=4, \n",
    "                           cv=skf.split(X, Y), verbose=3)\n",
    "        \n",
    "        my_model.fit(X, Y)\n",
    "        best_params = my_model.best_params_\n",
    "        # print(best_params)\n",
    "        \n",
    "    elif trainCV is 'grid':\n",
    "        X = np.concatenate((X_train, X_test), axis=0)\n",
    "        Y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "        \n",
    "        my_model = GridSearchCV(model, params, scoring='roc_auc', cv=skf.split(X,Y))\n",
    "                \n",
    "        my_model.fit(X, Y)\n",
    "        best_params = my_model.best_params_\n",
    "        # print(best_params)\n",
    "        \n",
    "    else:\n",
    "        my_model = model\n",
    "        \n",
    "        my_model.fit(X_train, y_train)\n",
    "\n",
    "#         eval_set=[(X_train, y_train), (X_test, y_test)]\n",
    "#         my_model.fit(X_train, y_train, eval_set=eval_set, \n",
    "#                      eval_metric=\"auc\", early_stopping_rounds=15, verbose=False)\n",
    "        \n",
    "        best_params = params\n",
    "    \n",
    "    train_pred = my_model.predict(X_train)\n",
    "    test_pred = my_model.predict(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_train, train_pred, pos_label=1)\n",
    "    train_auc_score = auc(fpr, tpr)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, test_pred, pos_label=1)\n",
    "    test_auc_score = auc(fpr, tpr)\n",
    "    \n",
    "    train_auc = train_auc_score\n",
    "    test_auc = test_auc_score\n",
    "    \n",
    "    train_acc = my_model.score(X_train, y_train)\n",
    "    test_acc = my_model.score(X_test, y_test)\n",
    "    \n",
    "    test_metrics = confusion_matrix(y_test, test_pred).ravel()\n",
    "    train_metrics = confusion_matrix(y_train, train_pred).ravel()\n",
    "\n",
    "    return train_auc, test_auc, train_acc, test_acc, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = pd.read_csv('../../DataPlus/dvd_shared_slda_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Unnamed: 0.1',\n",
       " 'Tx3',\n",
       " 'Advice1',\n",
       " 'Anx11',\n",
       " 'Anx111',\n",
       " 'Anx112',\n",
       " 'Anx113',\n",
       " 'Anx12',\n",
       " 'Anx13',\n",
       " 'Anx51',\n",
       " 'Anx52',\n",
       " 'Anx53',\n",
       " 'Anx61',\n",
       " 'Anx62',\n",
       " 'Anx63',\n",
       " 'Anx71',\n",
       " 'Anx72',\n",
       " 'Anx73',\n",
       " 'Anx91',\n",
       " 'Anx92',\n",
       " 'Anx93',\n",
       " 'Ask3',\n",
       " 'Clear3',\n",
       " 'DA1',\n",
       " 'Dienot2',\n",
       " 'Doc1',\n",
       " 'Explain3',\n",
       " 'Finaltx3',\n",
       " 'ID',\n",
       " 'Involve3',\n",
       " 'MD_age',\n",
       " 'MD_gender',\n",
       " 'MD_number_pts_wk',\n",
       " 'MD_percentpts',\n",
       " 'MD_race',\n",
       " 'MD_specialty',\n",
       " 'MD_type',\n",
       " 'MD_yrgrad',\n",
       " 'Mdtxrec3',\n",
       " 'Opinion3',\n",
       " 'Raded2',\n",
       " 'Radpee2',\n",
       " 'Satis3',\n",
       " 'Study',\n",
       " 'Sured2',\n",
       " 'Surpee2',\n",
       " 'Talkda3',\n",
       " 'Timeda2',\n",
       " 'TxgotTx3cc',\n",
       " 'Txlean3',\n",
       " 'Wait2',\n",
       " 'Whyww2',\n",
       " 'Wwed2',\n",
       " 'Wwpee2',\n",
       " 'age',\n",
       " 'arabme',\n",
       " 'asian',\n",
       " 'black',\n",
       " 'education',\n",
       " 'gleason',\n",
       " 'hispanic',\n",
       " 'irespmd',\n",
       " 'marry',\n",
       " 'mdrespme',\n",
       " 'native',\n",
       " 'pacific',\n",
       " 'psa1',\n",
       " 'raceother',\n",
       " 'txgot',\n",
       " 'txgot_binary',\n",
       " 'white',\n",
       " 'Convo_1',\n",
       " 'Convo_2',\n",
       " 'Doctor_1',\n",
       " 'Doctor_2',\n",
       " 'Topic1',\n",
       " 'Topic2',\n",
       " 'Topic3',\n",
       " 'Topic4',\n",
       " 'Topic5',\n",
       " 'Topic6',\n",
       " 'Topic7',\n",
       " 'Topic8',\n",
       " 'Topic9',\n",
       " 'Topic10',\n",
       " 'Topic11',\n",
       " 'Topic12',\n",
       " 'Topic13',\n",
       " 'Topic14',\n",
       " 'Topic15']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(topics_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = ['gleason', 'DVD_UroRec_AS', 'DVD_UroRec_AS', 'DVD_UroRec_AS']\n",
    "cont1 = ['age', 'DVD_UroTalk_AS', 'DVD_UroTalk_surgery', 'DVD_UroTalk_rad']\n",
    "subset1 = ['Topic1', 'Topic3', 'Topic8', 'Topic12', 'Topic13', 'Topic14']\n",
    "subset2 = ['Topic4', 'Topic8', 'Topic12', 'Topic13', 'Topic14']\n",
    "subset3 = ['Topic3', 'Topic4', 'Topic6', 'Topic8', 'Topic9', 'Topic14', 'Topic15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['DVD_UroTalk_AS' 'DVD_UroTalk_surgery' 'DVD_UroTalk_rad' 'DVD_UroRec_AS'\\n 'DVD_UroRec_AS' 'DVD_UroRec_AS'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-91e5abf0a62f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfirst_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopics_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'txgot_binary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcont1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-6bb113924a34>\u001b[0m in \u001b[0;36mprepare_df\u001b[1;34m(df, target_var, cont_vars, cat_vars)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprepare_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcont_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtotal_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcont_vars\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcat_vars\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtarget_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtotal_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mcleaned_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataplus\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2678\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2679\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2680\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataplus\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2721\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2722\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2723\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dataplus\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['DVD_UroTalk_AS' 'DVD_UroTalk_surgery' 'DVD_UroTalk_rad' 'DVD_UroRec_AS'\\n 'DVD_UroRec_AS' 'DVD_UroRec_AS'] not in index\""
     ]
    }
   ],
   "source": [
    "first_df = prepare_df(topics_df, 'txgot_binary', subset1 + cont1, cat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'min_child_weight': [1, 2],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.5, 0.6],\n",
    "    'colsample_bytree': [0.1, 0.2, 0.3],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'n_estimators': [150, 160]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c3da6974ed42e692281f8ee47ba30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train vs. Test\n",
      "Training AUC: 0.674\n",
      "Testing AUC: 0.681\n",
      "\n",
      "Training Accuracy: 0.975\n",
      "Testing Accuracy: 0.974\n",
      "\n",
      "min_child_weight: {1: 175, 2: 25}\n",
      "gamma: {0: 78, 0.1: 63, 0.2: 59}\n",
      "subsample: {0.5: 98, 0.6: 102}\n",
      "colsample_bytree: {0.1: 70, 0.2: 56, 0.3: 74}\n",
      "max_depth: {2: 74, 3: 66, 4: 60}\n",
      "n_estimators: {150: 94, 160: 106}\n",
      "\n",
      "Feature Importance:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6744916666666663, 0.6810714285714288)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb4 = XGBClassifier(learning_rate=0.02, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "xgbclassify(first_df, xgb4, params=grid_params, \n",
    "            trainCV='grid', iterations=40, print_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataPlus",
   "language": "python",
   "name": "dataplus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

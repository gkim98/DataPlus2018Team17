{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process text for entire dataframe\n",
    "- Remove punctuation, parentheses and convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shamelessly borrowed code from 1) https://www2.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html  (tf-idf) 2)https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730 (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc1 = '!\"#$%\\'()*.:;<=>?@[\\\\]^`{|}~’“”‘–-'\n",
    "punc2 = ['=', '/', '&', '_', '+', '…', '...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords list \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "additional_list = ['doin','nn','rd','st','wheres','hows','clean','theyve', 'weve', 'youve', 'de','u', 'yer', 'stuff','cause','mhm', 'mmhm','itit', 'youyou', 'ah', 'ifif', 'there', 'kinda', 'le','ill', 'hell', 'shell', 'whats', 'isnt', 'thats', 'theyve', 'arent', 'couldnt', 'didnt', 'hadnt', 'hasnt', 'werent', 'havent','dont', 'wont', 'cant', 'wouldnt', 'id', 'ive', 'gonna', 'hed', 'shouldnt', 'ii','dr','cuz', 'im','youre', 'hes', 'shes', 'were', 'theyre', 'thethe','theyll', 'youll', 'andand', 'th', 'thatthat', 'sthat', 'wewe','ti','u', 'heh', 'le', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'ya','nd', 'uhh', 's','d','t','by', 'cancer', 'don', 're', 'prostate', 'oh', 'ah', 'ahh', 'm', 'ok', 'okay', 'md', 'like','uh','uhum', 'go', 'got', 'yeah', 'okay', 'yep','uhm', 'umm', 'hum', 'na', 'um', 'legend', 'hmm', 'ah', 'na', 'mm', 'mmm', 'da', 'mmhmm', 'mmmhmm', 'yup', 'hm', 'know', 'would', 'get', 'other', 'huh']\n",
    "stop_words.extend(additional_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to help with processing text\n",
    "def remove_parentheses(txt):\n",
    "    txt = re.sub('\\([^)]*\\)\\)','', txt) # remove double parentheses \n",
    "    txt = re.sub(r'\\([^)]*\\)', '', txt) # remove single parentheses \n",
    "    return txt\n",
    "\n",
    "def remove_numerical(txt):\n",
    "    txt = re.sub('[0-9]+', '', txt)\n",
    "    return txt\n",
    "\n",
    "def remove_punc(txt):\n",
    "    for a in punc2:\n",
    "        txt = txt.replace(a,\" \")\n",
    "    for b in punc1:\n",
    "        txt = txt.replace(b,\"\")\n",
    "    return txt\n",
    "\n",
    "def lowercase(txt):\n",
    "    txt = txt.lower()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>Convo_1</th>\n",
       "      <th>Convo_2</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Doctor_1</th>\n",
       "      <th>Doctor_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A003</td>\n",
       "      <td>A003 LEGEND: MD2=Physician PT=Patient MD2: So ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A004</td>\n",
       "      <td>A004 LEGEND: MD2=Physician OTH=Study staff-set...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A014</td>\n",
       "      <td>A014 LEGEND: MD2=Physician PT=Patient MD2: Tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A015</td>\n",
       "      <td>A015_CLEAN LEGEND: MD2=Physician PT=Patient MD...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A016</td>\n",
       "      <td>A016_CLEAN_LOUD LEGEND: MD2=Physician PT: Pati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 patient_id                                            Convo_1  \\\n",
       "0           0       A003  A003 LEGEND: MD2=Physician PT=Patient MD2: So ...   \n",
       "1           1       A004  A004 LEGEND: MD2=Physician OTH=Study staff-set...   \n",
       "2           2       A014  A014 LEGEND: MD2=Physician PT=Patient MD2: Tha...   \n",
       "3           3       A015  A015_CLEAN LEGEND: MD2=Physician PT=Patient MD...   \n",
       "4           4       A016  A016_CLEAN_LOUD LEGEND: MD2=Physician PT: Pati...   \n",
       "\n",
       "  Convo_2 Dataset Doctor_1 Doctor_2  \n",
       "0     NaN      VA        U      NaN  \n",
       "1     NaN      VA        U      NaN  \n",
       "2     NaN      VA        U      NaN  \n",
       "3     NaN      VA        U      NaN  \n",
       "4     NaN      VA        U      NaN  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# clean up each of the convo_1 texts with the processing functions written above\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['Convo_1']) == False:\n",
    "        row['Convo_1'] = remove_parentheses(row['Convo_1'])\n",
    "        row['Convo_1'] = remove_numerical(row['Convo_1'])\n",
    "        row['Convo_1'] = remove_punc(row['Convo_1'])\n",
    "        row['Convo_1'] = lowercase(row['Convo_1'])\n",
    "        df.set_value(index,'Convo_1', row['Convo_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing, removing stopwords, stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment on one documet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>Convo_1</th>\n",
       "      <th>Convo_2</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Doctor_1</th>\n",
       "      <th>Doctor_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A003</td>\n",
       "      <td>a legend md physician pt patient md so thank y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A004</td>\n",
       "      <td>a legend md physician oth study staff setting ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A014</td>\n",
       "      <td>a legend md physician pt patient md thank you ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A015</td>\n",
       "      <td>aclean legend md physician pt patient md so it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A016</td>\n",
       "      <td>acleanloud legend md physician pt patient md o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 patient_id                                            Convo_1  \\\n",
       "0           0       A003  a legend md physician pt patient md so thank y...   \n",
       "1           1       A004  a legend md physician oth study staff setting ...   \n",
       "2           2       A014  a legend md physician pt patient md thank you ...   \n",
       "3           3       A015  aclean legend md physician pt patient md so it...   \n",
       "4           4       A016  acleanloud legend md physician pt patient md o...   \n",
       "\n",
       "  Convo_2 Dataset Doctor_1 Doctor_2  \n",
       "0     NaN      VA        U      NaN  \n",
       "1     NaN      VA        U      NaN  \n",
       "2     NaN      VA        U      NaN  \n",
       "3     NaN      VA        U      NaN  \n",
       "4     NaN      VA        U      NaN  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_0 = df['Convo_1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'legend',\n",
       " 'md',\n",
       " 'physician',\n",
       " 'pt',\n",
       " 'patient',\n",
       " 'md',\n",
       " 'so',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'for',\n",
       " 'coming',\n",
       " 'in',\n",
       " 'i',\n",
       " 'know',\n",
       " 'we',\n",
       " 'kinda',\n",
       " 'moved',\n",
       " 'your',\n",
       " 'appointment',\n",
       " 'upbut',\n",
       " 'next',\n",
       " 'week',\n",
       " 'our',\n",
       " 'clinic',\n",
       " 'was',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'overbooked',\n",
       " 'and',\n",
       " 'we',\n",
       " 'didn',\n",
       " 't',\n",
       " 'have',\n",
       " 'staff',\n",
       " 'to',\n",
       " 'bring',\n",
       " 'people',\n",
       " 'in',\n",
       " 'dr',\n",
       " 'pt',\n",
       " 'okay',\n",
       " 'md',\n",
       " 'um',\n",
       " 'so',\n",
       " 'ah',\n",
       " 'we',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'bring',\n",
       " 'you',\n",
       " 'in',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'your',\n",
       " 'biopsy',\n",
       " 'results',\n",
       " 'um',\n",
       " 'as',\n",
       " 'we',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'expected',\n",
       " 'with',\n",
       " 'your',\n",
       " 'psa',\n",
       " 'being',\n",
       " 'up',\n",
       " 'there',\n",
       " 'was',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sample',\n",
       " 'pt',\n",
       " 'okay',\n",
       " 'md',\n",
       " 'um',\n",
       " 'the',\n",
       " 'ah',\n",
       " 'you',\n",
       " 'know',\n",
       " 'the',\n",
       " 'exam',\n",
       " 'that',\n",
       " 'they',\n",
       " 'did',\n",
       " 'they',\n",
       " 'could',\n",
       " 'feel',\n",
       " 'a',\n",
       " 'little',\n",
       " 'area',\n",
       " 'that',\n",
       " 'felt',\n",
       " 'abnormal',\n",
       " 'on',\n",
       " 'the',\n",
       " 'left',\n",
       " 'side',\n",
       " 'of',\n",
       " 'your',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'and',\n",
       " 'that',\n",
       " 's',\n",
       " 'where',\n",
       " 'the',\n",
       " 'biopsies',\n",
       " 'were',\n",
       " 'positive',\n",
       " 'nd',\n",
       " 'uhh',\n",
       " 'at',\n",
       " 'this',\n",
       " 'point',\n",
       " 'we',\n",
       " 're',\n",
       " 'pt',\n",
       " 'md',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'talk',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'about',\n",
       " 'how',\n",
       " 'we',\n",
       " 'grade',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'what',\n",
       " 'it',\n",
       " 'means',\n",
       " 'what',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'treatment',\n",
       " 'options',\n",
       " 'we',\n",
       " 'have',\n",
       " 'i',\n",
       " 'know',\n",
       " 'that',\n",
       " 'um',\n",
       " 'she',\n",
       " 's',\n",
       " 'probably',\n",
       " 'given',\n",
       " 'you',\n",
       " 'an',\n",
       " 'instruction',\n",
       " 'or',\n",
       " 'at',\n",
       " 'least',\n",
       " 'some',\n",
       " 'handouts',\n",
       " 'that',\n",
       " 'kinda',\n",
       " 'go',\n",
       " 'over',\n",
       " 'you',\n",
       " 'know',\n",
       " 'how',\n",
       " 'we',\n",
       " 'treat',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'and',\n",
       " 'she—if',\n",
       " 'she',\n",
       " 'hasn',\n",
       " 't',\n",
       " 'yet—she',\n",
       " 'll',\n",
       " 'give',\n",
       " 'you',\n",
       " 'the',\n",
       " 'educational',\n",
       " 'today',\n",
       " 'pt',\n",
       " 'md',\n",
       " 'um',\n",
       " 'in',\n",
       " 'general',\n",
       " 'we',\n",
       " 'grade',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'how',\n",
       " 'it',\n",
       " 'looks',\n",
       " 'under',\n",
       " 'the',\n",
       " 'microscope',\n",
       " 'so',\n",
       " 'we',\n",
       " 'lump',\n",
       " 'prostate',\n",
       " 'cancers',\n",
       " 'into',\n",
       " 'risk',\n",
       " 'categories',\n",
       " 'we',\n",
       " 'call',\n",
       " 'them',\n",
       " 'either',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'um',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'or',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'um',\n",
       " 'and',\n",
       " 'we',\n",
       " 'do',\n",
       " 'that',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'psa',\n",
       " 'level',\n",
       " 'and',\n",
       " 'how',\n",
       " 'they',\n",
       " 'look',\n",
       " 'under',\n",
       " 'the',\n",
       " 'microscope',\n",
       " 'in',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'histology',\n",
       " 'pt',\n",
       " 'mmhm',\n",
       " 'md',\n",
       " 'your',\n",
       " 'psa',\n",
       " 'level',\n",
       " 'is',\n",
       " 'a',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'category',\n",
       " 'anything',\n",
       " 'below',\n",
       " 'ten',\n",
       " 'we',\n",
       " 'consider',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'for',\n",
       " 'psa',\n",
       " 'see',\n",
       " 'people',\n",
       " 'who',\n",
       " 'present',\n",
       " 'with',\n",
       " 'psas',\n",
       " 'in',\n",
       " 'the',\n",
       " 's',\n",
       " 'and',\n",
       " 's',\n",
       " 'pt',\n",
       " 'mmhm',\n",
       " 'md',\n",
       " 'they',\n",
       " 're',\n",
       " 'more',\n",
       " 'of',\n",
       " 'a',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'pt',\n",
       " 'and',\n",
       " 'my',\n",
       " 'psa',\n",
       " 'is',\n",
       " 'at',\n",
       " 'md',\n",
       " 'your',\n",
       " 'psa',\n",
       " 'was',\n",
       " 'like',\n",
       " 'around',\n",
       " 'four',\n",
       " 'and',\n",
       " 'a',\n",
       " 'half',\n",
       " 'so',\n",
       " 'it',\n",
       " 'was',\n",
       " 'below',\n",
       " 'five',\n",
       " 'below',\n",
       " 'well',\n",
       " 'well',\n",
       " 'below',\n",
       " 'ten',\n",
       " 'um',\n",
       " 'your',\n",
       " 'um',\n",
       " 'gleason',\n",
       " 'score—which',\n",
       " 'is',\n",
       " 'how',\n",
       " 'it',\n",
       " 'looks',\n",
       " 'under',\n",
       " 'the',\n",
       " 'microscope—they',\n",
       " 'grade',\n",
       " 'them',\n",
       " 'on',\n",
       " 'a',\n",
       " 'scale',\n",
       " 'that',\n",
       " 'runs',\n",
       " 'from',\n",
       " 'basically',\n",
       " 'six',\n",
       " 'to',\n",
       " 'ten',\n",
       " 'um',\n",
       " 'they',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'most',\n",
       " 'common',\n",
       " 'appearance',\n",
       " 'under',\n",
       " 'the',\n",
       " 'microscope',\n",
       " 'the',\n",
       " 'appearances',\n",
       " 'are',\n",
       " 'graded',\n",
       " 'from',\n",
       " 'one',\n",
       " 'to',\n",
       " 'five',\n",
       " 'with',\n",
       " 'five',\n",
       " 'being',\n",
       " 'the',\n",
       " 'most',\n",
       " 'aggressive',\n",
       " 'cancer',\n",
       " 'and',\n",
       " 'one',\n",
       " 'being',\n",
       " 'just',\n",
       " 'a',\n",
       " 'little',\n",
       " 'abnormal',\n",
       " 'not',\n",
       " 'even',\n",
       " 'really',\n",
       " 'cancer',\n",
       " 'cancers',\n",
       " 'are',\n",
       " 'only',\n",
       " 'three',\n",
       " 'four',\n",
       " 'and',\n",
       " 'five',\n",
       " 'and',\n",
       " 'so',\n",
       " 'the',\n",
       " 'gleason',\n",
       " 'score',\n",
       " 'they',\n",
       " 'grade',\n",
       " 'the',\n",
       " 'most',\n",
       " 'common',\n",
       " 'and',\n",
       " 'the',\n",
       " 'second',\n",
       " 'most',\n",
       " 'common',\n",
       " 'appearance',\n",
       " 'on',\n",
       " 'the',\n",
       " 'microscope',\n",
       " 'so',\n",
       " 'the',\n",
       " 'least',\n",
       " 'aggressive',\n",
       " 'cancer',\n",
       " 'you',\n",
       " 'can',\n",
       " 'have',\n",
       " 'is',\n",
       " 'three',\n",
       " 'plus',\n",
       " 'three—or',\n",
       " 'six—as',\n",
       " 'a',\n",
       " 'gleason',\n",
       " 'score',\n",
       " 'the',\n",
       " 'most',\n",
       " 'aggressive',\n",
       " 'you',\n",
       " 'could',\n",
       " 'have',\n",
       " 'would',\n",
       " 'be',\n",
       " 'five',\n",
       " 'plus',\n",
       " 'five',\n",
       " 'or',\n",
       " 'ten',\n",
       " 'so',\n",
       " 'in',\n",
       " 'reality',\n",
       " 'they',\n",
       " 'end',\n",
       " 'up',\n",
       " 'grading',\n",
       " 'things',\n",
       " 'from',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'nine',\n",
       " 'and',\n",
       " 'ten',\n",
       " 'all',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'first',\n",
       " 'number',\n",
       " 'and',\n",
       " 'the',\n",
       " 'second',\n",
       " 'number',\n",
       " 'um',\n",
       " 'yours',\n",
       " 'was',\n",
       " 'three',\n",
       " 'plus',\n",
       " 'four',\n",
       " 'um',\n",
       " 'so',\n",
       " 'that',\n",
       " 'puts',\n",
       " 'you',\n",
       " 'in',\n",
       " 'the',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'category',\n",
       " 'pt',\n",
       " 'yeah',\n",
       " 'med',\n",
       " 'of',\n",
       " 'aggressive',\n",
       " 'so',\n",
       " 'the',\n",
       " 'cells',\n",
       " 'split',\n",
       " 'the',\n",
       " 'cell',\n",
       " 'split',\n",
       " 'rate',\n",
       " 'is',\n",
       " 'than',\n",
       " 'normal',\n",
       " 'okay',\n",
       " 'md',\n",
       " 'and',\n",
       " 'i',\n",
       " 'm',\n",
       " 'recording',\n",
       " 'right',\n",
       " 'now',\n",
       " 'no',\n",
       " 'uhm',\n",
       " 'pt',\n",
       " 'ready',\n",
       " 'set',\n",
       " 'oh',\n",
       " 'md',\n",
       " 'so',\n",
       " 'uhm',\n",
       " 'at',\n",
       " 'this',\n",
       " 'point',\n",
       " 'ah',\n",
       " 'you',\n",
       " 're',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'in',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'how',\n",
       " 'it',\n",
       " 'appears',\n",
       " 'under',\n",
       " 'the',\n",
       " 'microscope',\n",
       " 'you',\n",
       " 're',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'on',\n",
       " 'how',\n",
       " 'it',\n",
       " 'is',\n",
       " 'in',\n",
       " 'psa',\n",
       " 'and',\n",
       " 'so',\n",
       " 'we',\n",
       " 'would',\n",
       " 'c',\n",
       " 'categorize',\n",
       " 'you',\n",
       " 'overall',\n",
       " 'as',\n",
       " 'an',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'patient',\n",
       " 'uhm',\n",
       " 'if',\n",
       " 'you',\n",
       " 'were',\n",
       " 'four',\n",
       " 'plus',\n",
       " 'four',\n",
       " 'or',\n",
       " 'higher',\n",
       " 'we',\n",
       " 'start',\n",
       " 'to',\n",
       " 'look',\n",
       " 'at',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'categories',\n",
       " 'and',\n",
       " 'worry',\n",
       " 'more',\n",
       " 'about',\n",
       " 'spread',\n",
       " 'um',\n",
       " 'at',\n",
       " 'this',\n",
       " 'point',\n",
       " 'spread',\n",
       " 'for',\n",
       " 'you',\n",
       " 'would',\n",
       " 'still',\n",
       " 'be',\n",
       " 'very',\n",
       " 'rare',\n",
       " 'um',\n",
       " 'still',\n",
       " 'probably',\n",
       " 'under',\n",
       " 'or',\n",
       " 'where',\n",
       " 'there',\n",
       " 's',\n",
       " 'starting',\n",
       " 'to',\n",
       " 'be',\n",
       " 'spread',\n",
       " 'outside',\n",
       " 'the',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'into',\n",
       " 'lymph',\n",
       " 'nodes',\n",
       " 'and',\n",
       " 'things',\n",
       " 'like',\n",
       " 'that',\n",
       " 'but',\n",
       " 'it',\n",
       " 'certainly',\n",
       " 'can',\n",
       " 'happen',\n",
       " 'pt',\n",
       " 'yeah',\n",
       " 'it',\n",
       " 'could',\n",
       " 'get',\n",
       " 'into',\n",
       " 'the',\n",
       " 'blood',\n",
       " 'and',\n",
       " 'start',\n",
       " 'travelling',\n",
       " 'md',\n",
       " 'it',\n",
       " 'could',\n",
       " 'start',\n",
       " 'to',\n",
       " 'spread',\n",
       " 'and',\n",
       " 'the',\n",
       " 'most',\n",
       " 'common',\n",
       " 'things',\n",
       " 'that',\n",
       " 'we',\n",
       " 'see',\n",
       " 'spread',\n",
       " 'to',\n",
       " 'are',\n",
       " 'the',\n",
       " 'lymph',\n",
       " 'nodes',\n",
       " 'that',\n",
       " 'are',\n",
       " 'around',\n",
       " 'the',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'and',\n",
       " 'and',\n",
       " 'then',\n",
       " 'further',\n",
       " 'away',\n",
       " 'it',\n",
       " 'starts',\n",
       " 'to',\n",
       " 'spread',\n",
       " 'to',\n",
       " 'places',\n",
       " 'like',\n",
       " 'the',\n",
       " 'bone',\n",
       " 'um',\n",
       " 'but',\n",
       " 'you',\n",
       " 'would',\n",
       " 'be',\n",
       " 'very',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'for',\n",
       " 'having',\n",
       " 'spread',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bone',\n",
       " 'at',\n",
       " 'this',\n",
       " 'point',\n",
       " 'um',\n",
       " 'so',\n",
       " 'treatment',\n",
       " 'options',\n",
       " 'that',\n",
       " 'typically',\n",
       " 'come',\n",
       " 'up',\n",
       " 'for',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'span',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'gambit',\n",
       " 'from',\n",
       " 'minimally',\n",
       " 'invasive',\n",
       " 'things',\n",
       " 'to',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'maximally',\n",
       " 'invasive',\n",
       " 'things',\n",
       " 'that',\n",
       " 'give',\n",
       " 'you',\n",
       " 'the',\n",
       " 'best',\n",
       " 'chance',\n",
       " 'of',\n",
       " 'long',\n",
       " 'term',\n",
       " 'cure',\n",
       " 'in',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'outcomes',\n",
       " 'overall',\n",
       " 'um',\n",
       " 'the',\n",
       " 'survival',\n",
       " 'rate',\n",
       " 'is',\n",
       " 'very',\n",
       " 'good',\n",
       " 'ten',\n",
       " 'fifteen',\n",
       " 'plus',\n",
       " 'years',\n",
       " 'down',\n",
       " 'the',\n",
       " 'road',\n",
       " 'um',\n",
       " 'in',\n",
       " 'fact',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 's',\n",
       " 'so',\n",
       " 'slow',\n",
       " 'growing',\n",
       " 'that',\n",
       " 'we',\n",
       " 'don',\n",
       " 't',\n",
       " 'even',\n",
       " 'really',\n",
       " 'recommend',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'it',\n",
       " 'as',\n",
       " 'people',\n",
       " 'get',\n",
       " 'older',\n",
       " 'and',\n",
       " 'older',\n",
       " 'because',\n",
       " 'the',\n",
       " 'chance',\n",
       " 'of',\n",
       " 'you',\n",
       " 'dying',\n",
       " 'from',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'is',\n",
       " 'low',\n",
       " 'enough',\n",
       " 'that',\n",
       " 'your',\n",
       " 'heart',\n",
       " 's',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'have',\n",
       " 'a',\n",
       " 'problem',\n",
       " 'or',\n",
       " 'you',\n",
       " 're',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'have',\n",
       " 'diabetes',\n",
       " 'or',\n",
       " 'something',\n",
       " 'like',\n",
       " 'that',\n",
       " 'now',\n",
       " 'you',\n",
       " 'appear',\n",
       " 'very',\n",
       " 'healthy',\n",
       " 'so',\n",
       " 'i',\n",
       " 'i',\n",
       " 'don',\n",
       " 't',\n",
       " 'think',\n",
       " 'that',\n",
       " 'that',\n",
       " 's',\n",
       " 'the',\n",
       " 'issue',\n",
       " 'for',\n",
       " 'you',\n",
       " 'and',\n",
       " 'you',\n",
       " 're',\n",
       " 'young',\n",
       " 'enough',\n",
       " 'that',\n",
       " 'we',\n",
       " 'need',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'treatment',\n",
       " 'so',\n",
       " 'that',\n",
       " 'kinda',\n",
       " 'rules',\n",
       " 'out',\n",
       " 'the',\n",
       " 'ya',\n",
       " 'know',\n",
       " 'the',\n",
       " 'typical',\n",
       " 'you',\n",
       " 'know',\n",
       " 'way',\n",
       " 'that',\n",
       " 'we',\n",
       " 'would',\n",
       " 'think',\n",
       " 'about',\n",
       " 'doing',\n",
       " 'it',\n",
       " 'in',\n",
       " 'someone',\n",
       " 'who',\n",
       " 's',\n",
       " 'almost',\n",
       " 'years',\n",
       " 'old',\n",
       " 'which',\n",
       " 'is',\n",
       " 'we',\n",
       " 'don',\n",
       " 't',\n",
       " 'even',\n",
       " 'really',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'know',\n",
       " 'about',\n",
       " 'it',\n",
       " 'we',\n",
       " 'don',\n",
       " 't',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'treat',\n",
       " 'it',\n",
       " 'because',\n",
       " 'the',\n",
       " 'treatment',\n",
       " 's',\n",
       " 'often',\n",
       " 'worse',\n",
       " 'than',\n",
       " 'just',\n",
       " 'letting',\n",
       " 'it',\n",
       " 'go',\n",
       " 'cuz',\n",
       " 'it',\n",
       " 'grows',\n",
       " 'so',\n",
       " 'slowly',\n",
       " 'pt',\n",
       " 'yeah',\n",
       " 'the',\n",
       " 'cure',\n",
       " 's',\n",
       " 'worse',\n",
       " 'than',\n",
       " 'the',\n",
       " 'disease',\n",
       " 'okay',\n",
       " 'md',\n",
       " 'so',\n",
       " 'for',\n",
       " 'you',\n",
       " 'there',\n",
       " 'is',\n",
       " 'a',\n",
       " 'treatment',\n",
       " 'that',\n",
       " 'would',\n",
       " 'be',\n",
       " 'similar',\n",
       " 'to',\n",
       " 'that',\n",
       " 'and',\n",
       " 'it',\n",
       " 's',\n",
       " 'called',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'um',\n",
       " 'the',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'we',\n",
       " 'uh',\n",
       " 'used',\n",
       " 'to',\n",
       " 'do',\n",
       " 'for',\n",
       " 'older',\n",
       " 'people',\n",
       " 'is',\n",
       " 'just',\n",
       " 'watching',\n",
       " 'and',\n",
       " 'waiting',\n",
       " 'until',\n",
       " 'things',\n",
       " 'got',\n",
       " 'worse',\n",
       " 'and',\n",
       " 'then',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'fix',\n",
       " 'it',\n",
       " 'is',\n",
       " 'watchful',\n",
       " 'waiting',\n",
       " 'and',\n",
       " 'that',\n",
       " 's',\n",
       " 'not',\n",
       " 'really',\n",
       " 'what',\n",
       " 'we',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'anymore',\n",
       " 'we',\n",
       " 've',\n",
       " 'moved',\n",
       " 'more',\n",
       " 'towards',\n",
       " 'what',\n",
       " 'we',\n",
       " 'call',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'which',\n",
       " 'is',\n",
       " 'where',\n",
       " 'we',\n",
       " 'follow',\n",
       " 'you',\n",
       " 'we',\n",
       " 'check',\n",
       " 'psas',\n",
       " 'we',\n",
       " 'do',\n",
       " 'repeat',\n",
       " 'biopsies',\n",
       " 'we',\n",
       " 'do',\n",
       " 'another',\n",
       " 'biopsy',\n",
       " 'at',\n",
       " 'say',\n",
       " 'six',\n",
       " 'months',\n",
       " 'just',\n",
       " 'to',\n",
       " 'check',\n",
       " 'and',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'there',\n",
       " 'was',\n",
       " 'no',\n",
       " 'change',\n",
       " 'and',\n",
       " 'then',\n",
       " 'we',\n",
       " 'd',\n",
       " 're',\n",
       " 'biopsy',\n",
       " 'year',\n",
       " 'after',\n",
       " 'year',\n",
       " 'i',\n",
       " 'm',\n",
       " 'not',\n",
       " 'saying',\n",
       " 'this',\n",
       " 'is',\n",
       " 'what',\n",
       " ...]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(convo_0)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['physician',\n",
       " 'patient',\n",
       " 'thank',\n",
       " 'coming',\n",
       " 'know',\n",
       " 'kinda',\n",
       " 'moved',\n",
       " 'appointment',\n",
       " 'upbut',\n",
       " 'next',\n",
       " 'week',\n",
       " 'clinic',\n",
       " 'kind',\n",
       " 'overbooked',\n",
       " 'staff',\n",
       " 'bring',\n",
       " 'people',\n",
       " 'dr',\n",
       " 'okay',\n",
       " 'ah',\n",
       " 'wanted',\n",
       " 'bring',\n",
       " 'talk',\n",
       " 'biopsy',\n",
       " 'results',\n",
       " 'kind',\n",
       " 'expected',\n",
       " 'psa',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'sample',\n",
       " 'okay',\n",
       " 'ah',\n",
       " 'know',\n",
       " 'exam',\n",
       " 'could',\n",
       " 'feel',\n",
       " 'little',\n",
       " 'area',\n",
       " 'felt',\n",
       " 'abnormal',\n",
       " 'left',\n",
       " 'side',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'biopsies',\n",
       " 'positive',\n",
       " 'nd',\n",
       " 'uhh',\n",
       " 'point',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'talk',\n",
       " 'kind',\n",
       " 'grade',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'means',\n",
       " 'kind',\n",
       " 'treatment',\n",
       " 'options',\n",
       " 'know',\n",
       " 'probably',\n",
       " 'given',\n",
       " 'instruction',\n",
       " 'least',\n",
       " 'handouts',\n",
       " 'kinda',\n",
       " 'go',\n",
       " 'know',\n",
       " 'treat',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'she—if',\n",
       " 'yet—she',\n",
       " 'give',\n",
       " 'educational',\n",
       " 'today',\n",
       " 'general',\n",
       " 'grade',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'looks',\n",
       " 'microscope',\n",
       " 'lump',\n",
       " 'prostate',\n",
       " 'cancers',\n",
       " 'risk',\n",
       " 'categories',\n",
       " 'call',\n",
       " 'either',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'based',\n",
       " 'psa',\n",
       " 'level',\n",
       " 'look',\n",
       " 'microscope',\n",
       " 'terms',\n",
       " 'histology',\n",
       " 'mmhm',\n",
       " 'psa',\n",
       " 'level',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'category',\n",
       " 'anything',\n",
       " 'ten',\n",
       " 'consider',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'psa',\n",
       " 'see',\n",
       " 'people',\n",
       " 'present',\n",
       " 'psas',\n",
       " 'mmhm',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'psa',\n",
       " 'psa',\n",
       " 'like',\n",
       " 'around',\n",
       " 'four',\n",
       " 'half',\n",
       " 'five',\n",
       " 'well',\n",
       " 'well',\n",
       " 'ten',\n",
       " 'gleason',\n",
       " 'score—which',\n",
       " 'looks',\n",
       " 'microscope—they',\n",
       " 'grade',\n",
       " 'scale',\n",
       " 'runs',\n",
       " 'basically',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'look',\n",
       " 'common',\n",
       " 'appearance',\n",
       " 'microscope',\n",
       " 'appearances',\n",
       " 'graded',\n",
       " 'one',\n",
       " 'five',\n",
       " 'five',\n",
       " 'aggressive',\n",
       " 'cancer',\n",
       " 'one',\n",
       " 'little',\n",
       " 'abnormal',\n",
       " 'even',\n",
       " 'really',\n",
       " 'cancer',\n",
       " 'cancers',\n",
       " 'three',\n",
       " 'four',\n",
       " 'five',\n",
       " 'gleason',\n",
       " 'score',\n",
       " 'grade',\n",
       " 'common',\n",
       " 'second',\n",
       " 'common',\n",
       " 'appearance',\n",
       " 'microscope',\n",
       " 'least',\n",
       " 'aggressive',\n",
       " 'cancer',\n",
       " 'three',\n",
       " 'plus',\n",
       " 'three—or',\n",
       " 'six—as',\n",
       " 'gleason',\n",
       " 'score',\n",
       " 'aggressive',\n",
       " 'could',\n",
       " 'would',\n",
       " 'five',\n",
       " 'plus',\n",
       " 'five',\n",
       " 'ten',\n",
       " 'reality',\n",
       " 'end',\n",
       " 'grading',\n",
       " 'things',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'based',\n",
       " 'first',\n",
       " 'number',\n",
       " 'second',\n",
       " 'number',\n",
       " 'three',\n",
       " 'plus',\n",
       " 'four',\n",
       " 'puts',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'category',\n",
       " 'yeah',\n",
       " 'med',\n",
       " 'aggressive',\n",
       " 'cells',\n",
       " 'split',\n",
       " 'cell',\n",
       " 'split',\n",
       " 'rate',\n",
       " 'normal',\n",
       " 'okay',\n",
       " 'recording',\n",
       " 'right',\n",
       " 'ready',\n",
       " 'set',\n",
       " 'oh',\n",
       " 'point',\n",
       " 'ah',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'terms',\n",
       " 'appears',\n",
       " 'microscope',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'psa',\n",
       " 'would',\n",
       " 'c',\n",
       " 'categorize',\n",
       " 'overall',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'patient',\n",
       " 'four',\n",
       " 'plus',\n",
       " 'four',\n",
       " 'higher',\n",
       " 'start',\n",
       " 'look',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'categories',\n",
       " 'worry',\n",
       " 'spread',\n",
       " 'point',\n",
       " 'spread',\n",
       " 'would',\n",
       " 'still',\n",
       " 'rare',\n",
       " 'still',\n",
       " 'probably',\n",
       " 'starting',\n",
       " 'spread',\n",
       " 'outside',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'lymph',\n",
       " 'nodes',\n",
       " 'things',\n",
       " 'like',\n",
       " 'certainly',\n",
       " 'happen',\n",
       " 'yeah',\n",
       " 'could',\n",
       " 'get',\n",
       " 'blood',\n",
       " 'start',\n",
       " 'travelling',\n",
       " 'could',\n",
       " 'start',\n",
       " 'spread',\n",
       " 'common',\n",
       " 'things',\n",
       " 'see',\n",
       " 'spread',\n",
       " 'lymph',\n",
       " 'nodes',\n",
       " 'around',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'away',\n",
       " 'starts',\n",
       " 'spread',\n",
       " 'places',\n",
       " 'like',\n",
       " 'bone',\n",
       " 'would',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'spread',\n",
       " 'bone',\n",
       " 'point',\n",
       " 'treatment',\n",
       " 'options',\n",
       " 'typically',\n",
       " 'come',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'span',\n",
       " 'whole',\n",
       " 'gambit',\n",
       " 'minimally',\n",
       " 'invasive',\n",
       " 'things',\n",
       " 'kind',\n",
       " 'maximally',\n",
       " 'invasive',\n",
       " 'things',\n",
       " 'give',\n",
       " 'best',\n",
       " 'chance',\n",
       " 'long',\n",
       " 'term',\n",
       " 'cure',\n",
       " 'terms',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'outcomes',\n",
       " 'overall',\n",
       " 'survival',\n",
       " 'rate',\n",
       " 'good',\n",
       " 'ten',\n",
       " 'fifteen',\n",
       " 'plus',\n",
       " 'years',\n",
       " 'road',\n",
       " 'fact',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'slow',\n",
       " 'growing',\n",
       " 'even',\n",
       " 'really',\n",
       " 'recommend',\n",
       " 'looking',\n",
       " 'people',\n",
       " 'get',\n",
       " 'older',\n",
       " 'older',\n",
       " 'chance',\n",
       " 'dying',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'low',\n",
       " 'enough',\n",
       " 'heart',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'problem',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'diabetes',\n",
       " 'something',\n",
       " 'like',\n",
       " 'appear',\n",
       " 'healthy',\n",
       " 'think',\n",
       " 'issue',\n",
       " 'young',\n",
       " 'enough',\n",
       " 'need',\n",
       " 'talk',\n",
       " 'treatment',\n",
       " 'kinda',\n",
       " 'rules',\n",
       " 'ya',\n",
       " 'know',\n",
       " 'typical',\n",
       " 'know',\n",
       " 'way',\n",
       " 'would',\n",
       " 'think',\n",
       " 'someone',\n",
       " 'almost',\n",
       " 'years',\n",
       " 'old',\n",
       " 'even',\n",
       " 'really',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'know',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'treat',\n",
       " 'treatment',\n",
       " 'often',\n",
       " 'worse',\n",
       " 'letting',\n",
       " 'go',\n",
       " 'cuz',\n",
       " 'grows',\n",
       " 'slowly',\n",
       " 'yeah',\n",
       " 'cure',\n",
       " 'worse',\n",
       " 'disease',\n",
       " 'okay',\n",
       " 'treatment',\n",
       " 'would',\n",
       " 'similar',\n",
       " 'called',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'thing',\n",
       " 'uh',\n",
       " 'used',\n",
       " 'older',\n",
       " 'people',\n",
       " 'watching',\n",
       " 'waiting',\n",
       " 'things',\n",
       " 'got',\n",
       " 'worse',\n",
       " 'trying',\n",
       " 'fix',\n",
       " 'watchful',\n",
       " 'waiting',\n",
       " 'really',\n",
       " 'focus',\n",
       " 'anymore',\n",
       " 'moved',\n",
       " 'towards',\n",
       " 'call',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'follow',\n",
       " 'check',\n",
       " 'psas',\n",
       " 'repeat',\n",
       " 'biopsies',\n",
       " 'another',\n",
       " 'biopsy',\n",
       " 'say',\n",
       " 'six',\n",
       " 'months',\n",
       " 'check',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'change',\n",
       " 'biopsy',\n",
       " 'year',\n",
       " 'year',\n",
       " 'saying',\n",
       " 'recommend',\n",
       " 'going',\n",
       " 'talk',\n",
       " 'wanted',\n",
       " 'know',\n",
       " 'options',\n",
       " 'may',\n",
       " 'see',\n",
       " 'computer',\n",
       " 'internet',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'designed',\n",
       " 'delay',\n",
       " 'treating',\n",
       " 'cancer',\n",
       " 'live',\n",
       " 'live',\n",
       " 'normally',\n",
       " 'right',\n",
       " 'normal',\n",
       " 'sexual',\n",
       " 'function',\n",
       " 'normal',\n",
       " 'erectile',\n",
       " 'function',\n",
       " 'normal',\n",
       " 'urinary',\n",
       " 'control',\n",
       " 'things',\n",
       " 'cancer',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'getting',\n",
       " 'aggressive',\n",
       " 'enough',\n",
       " 'need',\n",
       " 'something',\n",
       " 'even',\n",
       " 'really',\n",
       " 'qualify',\n",
       " 'biopsy',\n",
       " 'results',\n",
       " 'enough',\n",
       " 'cores',\n",
       " 'four',\n",
       " 'cores',\n",
       " 'cancer',\n",
       " 'four',\n",
       " 'twelve',\n",
       " 'samples',\n",
       " 'took',\n",
       " 'cancer',\n",
       " 'enough',\n",
       " 'cancer',\n",
       " 'core',\n",
       " 'like',\n",
       " 'core',\n",
       " 'long',\n",
       " 'talking',\n",
       " 'half',\n",
       " 'core',\n",
       " 'cancer',\n",
       " 'means',\n",
       " 'little',\n",
       " 'more—higher',\n",
       " 'risk',\n",
       " 'someone',\n",
       " 'would',\n",
       " 'typically',\n",
       " 'put',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'know',\n",
       " 'particularly',\n",
       " 'think',\n",
       " 'best',\n",
       " 'option',\n",
       " 'best',\n",
       " 'options',\n",
       " 'would',\n",
       " 'one',\n",
       " 'two',\n",
       " 'forms',\n",
       " 'active',\n",
       " 'treatment',\n",
       " 'offer',\n",
       " 'va',\n",
       " 'surgery',\n",
       " 'remove',\n",
       " 'prostate',\n",
       " 'radiation',\n",
       " 'therapy',\n",
       " 'radiation',\n",
       " 'therapy',\n",
       " 'external',\n",
       " 'beam',\n",
       " 'radiation',\n",
       " 'therapy',\n",
       " 'imrt',\n",
       " 'proton',\n",
       " 'radiation',\n",
       " 'proton',\n",
       " 'radiation',\n",
       " 'proton',\n",
       " 'four',\n",
       " 'five',\n",
       " 'centers',\n",
       " 'u',\n",
       " 'know',\n",
       " 'ss',\n",
       " 'okay',\n",
       " 'go',\n",
       " 'ahead',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'offend',\n",
       " 'anyone',\n",
       " 'va',\n",
       " 'system',\n",
       " 'ahh',\n",
       " 'seek',\n",
       " 'proton',\n",
       " 'radiation',\n",
       " 'dr',\n",
       " 'grants',\n",
       " 'er',\n",
       " 'anything',\n",
       " 'va',\n",
       " 'would',\n",
       " 'provide',\n",
       " 'know',\n",
       " 'situation']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = [w for w in tokens if not w in stopwords_comprehensive]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cancer', 17), ('risk', 15), ('prostate', 13), ('know', 11), ('would', 9), ('four', 8), ('psa', 7), ('five', 7), ('things', 7), ('spread', 7), ('na', 6), ('treatment', 6), ('low', 6), ('ten', 6), ('like', 6), ('radiation', 6), ('kind', 5), ('okay', 5), ('microscope', 5), ('intermediate', 5), ('aggressive', 5), ('really', 5), ('plus', 5), ('enough', 5), ('active', 5), ('people', 4), ('talk', 4), ('biopsy', 4), ('could', 4), ('point', 4), ('gon', 4), ('grade', 4), ('options', 4), ('common', 4), ('even', 4), ('normal', 4), ('surveillance', 4), ('proton', 4), ('kinda', 3), ('ah', 3), ('little', 3), ('gland', 3), ('go', 3), ('looks', 3), ('high', 3), ('look', 3), ('terms', 3), ('see', 3), ('gleason', 3), ('six', 3), ('one', 3), ('three', 3), ('yeah', 3), ('start', 3), ('best', 3), ('older', 3), ('think', 3), ('worse', 3), ('core', 3), ('va', 3), ('therapy', 3), ('patient', 2), ('moved', 2), ('bring', 2), ('dr', 2), ('wanted', 2), ('results', 2), ('abnormal', 2), ('biopsies', 2), ('means', 2), ('probably', 2), ('least', 2), ('treat', 2), ('give', 2), ('cancers', 2), ('categories', 2), ('call', 2), ('based', 2), ('level', 2), ('mmhm', 2), ('category', 2), ('anything', 2), ('psas', 2), ('around', 2), ('half', 2), ('well', 2), ('appearance', 2), ('score', 2), ('second', 2), ('number', 2), ('split', 2), ('rate', 2), ('right', 2), ('overall', 2), ('still', 2), ('lymph', 2), ('nodes', 2), ('get', 2), ('bone', 2), ('typically', 2)]\n"
     ]
    }
   ],
   "source": [
    "# check most common words see if there is anything we should add to stopwords list\n",
    "count = Counter(filtered)\n",
    "print(count.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cancer', 19), ('risk', 15), ('prostat', 13), ('know', 11), ('psa', 9), ('would', 9), ('four', 8), ('thing', 8), ('look', 7), ('five', 7), ('spread', 7), ('biopsi', 6), ('na', 6), ('grade', 6), ('treatment', 6), ('low', 6), ('ten', 6), ('like', 6), ('radiat', 6), ('kind', 5), ('okay', 5), ('talk', 5), ('option', 5), ('microscop', 5), ('intermedi', 5), ('appear', 5), ('aggress', 5), ('realli', 5), ('plu', 5), ('normal', 5), ('start', 5), ('enough', 5), ('activ', 5), ('core', 5), ('peopl', 4), ('could', 4), ('point', 4), ('gon', 4), ('go', 4), ('categori', 4), ('term', 4), ('common', 4), ('even', 4), ('year', 4), ('surveil', 4), ('proton', 4), ('kinda', 3), ('ah', 3), ('littl', 3), ('gland', 3), ('treat', 3), ('call', 3), ('high', 3), ('see', 3), ('gleason', 3), ('six', 3), ('one', 3), ('three', 3), ('yeah', 3), ('get', 3), ('typic', 3), ('best', 3), ('older', 3), ('think', 3), ('wors', 3), ('va', 3), ('therapi', 3), ('patient', 2), ('come', 2), ('move', 2), ('bring', 2), ('dr', 2), ('want', 2), ('result', 2), ('sampl', 2), ('abnorm', 2), ('mean', 2), ('probabl', 2), ('least', 2), ('give', 2), ('base', 2), ('level', 2), ('mmhm', 2), ('anyth', 2), ('around', 2), ('half', 2), ('well', 2), ('score', 2), ('second', 2), ('number', 2), ('put', 2), ('cell', 2), ('split', 2), ('rate', 2), ('right', 2), ('overal', 2), ('still', 2), ('lymph', 2), ('node', 2), ('bone', 2)]\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed = stem_tokens(filtered, stemmer)\n",
    "count = Counter(stemmed)\n",
    "print(count.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to process entire conversation 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nona = df.dropna(subset=['Convo_1'])\n",
    "conversations = df_nona['Convo_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords_comprehensive = stopwords_comprehensive = stopwords.words('english') + added_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    #stems = stem_tokens(tokens, stemmer)\n",
    "    lemmas = lemma_tokens(tokens,lemmatizer)\n",
    "    #return stems\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_tokens(tokens, lemmatizer):\n",
    "    lemmed = []\n",
    "    for item in tokens:\n",
    "        lemmed.append(lemmatizer.lemmatize(item))\n",
    "    return lemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize, max_features=5000, stop_words = stopwords_comprehensive)\n",
    "tf = tfidf.fit_transform(conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_feature_names = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n] # get indices of biggest tf-idf coefficients \n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids] # get corresponding feature/value tuple based off indices\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>right</td>\n",
       "      <td>0.314188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prostate</td>\n",
       "      <td>0.230405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cancer</td>\n",
       "      <td>0.195495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>six</td>\n",
       "      <td>0.189217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spinal</td>\n",
       "      <td>0.150540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wa</td>\n",
       "      <td>0.147682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sphincter</td>\n",
       "      <td>0.145536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>0.141668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>year</td>\n",
       "      <td>0.140312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>going</td>\n",
       "      <td>0.137529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>psa</td>\n",
       "      <td>0.134110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kind</td>\n",
       "      <td>0.125445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ultrasound</td>\n",
       "      <td>0.122858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>got</td>\n",
       "      <td>0.119784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>flow</td>\n",
       "      <td>0.111216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rod</td>\n",
       "      <td>0.109470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.107795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>surgery</td>\n",
       "      <td>0.105487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>well</td>\n",
       "      <td>0.105234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>see</td>\n",
       "      <td>0.104729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>two</td>\n",
       "      <td>0.103703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>something</td>\n",
       "      <td>0.099885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>say</td>\n",
       "      <td>0.099646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>risk</td>\n",
       "      <td>0.093422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>good</td>\n",
       "      <td>0.092084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature     tfidf\n",
       "0        right  0.314188\n",
       "1     prostate  0.230405\n",
       "2       cancer  0.195495\n",
       "3          six  0.189217\n",
       "4       spinal  0.150540\n",
       "5           wa  0.147682\n",
       "6    sphincter  0.145536\n",
       "7       biopsy  0.141668\n",
       "8         year  0.140312\n",
       "9        going  0.137529\n",
       "10         psa  0.134110\n",
       "11        kind  0.125445\n",
       "12  ultrasound  0.122858\n",
       "13         got  0.119784\n",
       "14        flow  0.111216\n",
       "15         rod  0.109470\n",
       "16        mean  0.107795\n",
       "17     surgery  0.105487\n",
       "18        well  0.105234\n",
       "19         see  0.104729\n",
       "20         two  0.103703\n",
       "21   something  0.099885\n",
       "22         say  0.099646\n",
       "23        risk  0.093422\n",
       "24        good  0.092084"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_in_doc(tf, tf_feature_names, 2, top_n=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "IDF(t) = log(Total number of documents / Number of documents with term t in it).\n",
    "To compute, multiply TF(t)*IDF(t) for each term. We get higher tf-idf scores for terms that are really important to certain documents (both in that they appear in few other documents, and appear a lot in a single document). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary of Most Common Words Across Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the most common words can help filter out stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter()\n",
    "for conversation in conversations:\n",
    "    tokens = nltk.word_tokenize(conversation)\n",
    "    for token in tokens:\n",
    "        word_counts[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 75168),\n",
       " ('the', 70764),\n",
       " ('pt', 52826),\n",
       " ('that', 52007),\n",
       " ('i', 50004),\n",
       " ('md', 49193),\n",
       " ('and', 48874),\n",
       " ('to', 45077),\n",
       " ('it', 41444),\n",
       " ('a', 39997),\n",
       " ('of', 36243),\n",
       " ('s', 34364),\n",
       " ('so', 33079),\n",
       " ('we', 26457),\n",
       " ('is', 24915),\n",
       " ('okay', 22918),\n",
       " ('in', 21077),\n",
       " ('know', 20829),\n",
       " ('have', 20566),\n",
       " ('um', 19896),\n",
       " ('yeah', 16816),\n",
       " ('t', 15609),\n",
       " ('your', 15194),\n",
       " ('do', 15084),\n",
       " ('for', 13613),\n",
       " ('but', 13266),\n",
       " ('if', 12970),\n",
       " ('prostate', 12965),\n",
       " ('they', 12710),\n",
       " ('there', 12441),\n",
       " ('with', 12360),\n",
       " ('or', 12285),\n",
       " ('cancer', 12035),\n",
       " ('what', 12012),\n",
       " ('right', 11458),\n",
       " ('be', 11097),\n",
       " ('can', 10878),\n",
       " ('about', 10813),\n",
       " ('not', 10629),\n",
       " ('re', 10626),\n",
       " ('surgery', 10335),\n",
       " ('are', 9900),\n",
       " ('on', 9524),\n",
       " ('like', 9469),\n",
       " ('just', 9424),\n",
       " ('this', 9380),\n",
       " ('radiation', 9341),\n",
       " ('would', 9322),\n",
       " ('then', 8418),\n",
       " ('don', 8044),\n",
       " ('at', 7879),\n",
       " ('get', 7783),\n",
       " ('no', 7754),\n",
       " ('hmm', 7684),\n",
       " ('was', 7512),\n",
       " ('think', 7012),\n",
       " ('uh', 6874),\n",
       " ('all', 6766),\n",
       " ('well', 6633),\n",
       " ('one', 6580),\n",
       " ('m', 6086),\n",
       " ('here', 5969),\n",
       " ('out', 5929),\n",
       " ('some', 5897),\n",
       " ('as', 5812),\n",
       " ('had', 5798),\n",
       " ('now', 5634),\n",
       " ('go', 5628),\n",
       " ('ll', 5609),\n",
       " ('he', 5541),\n",
       " ('good', 5340),\n",
       " ('because', 5327),\n",
       " ('my', 5287),\n",
       " ('up', 5277),\n",
       " ('more', 5038),\n",
       " ('kind', 4900),\n",
       " ('going', 4873),\n",
       " ('me', 4858),\n",
       " ('mm', 4841),\n",
       " ('see', 4707),\n",
       " ('when', 4638),\n",
       " ('very', 4574),\n",
       " ('any', 4567),\n",
       " ('from', 4478),\n",
       " ('how', 4445),\n",
       " ('other', 4385),\n",
       " ('risk', 4355),\n",
       " ('back', 4351),\n",
       " ('want', 4184),\n",
       " ('oth', 4151),\n",
       " ('treatment', 4137),\n",
       " ('little', 4085),\n",
       " ('time', 3990),\n",
       " ('biopsy', 3958),\n",
       " ('after', 3888),\n",
       " ('mean', 3848),\n",
       " ('say', 3815),\n",
       " ('an', 3807),\n",
       " ('people', 3734),\n",
       " ('oh', 3697),\n",
       " ('take', 3562),\n",
       " ('years', 3536),\n",
       " ('ve', 3517),\n",
       " ('things', 3490),\n",
       " ('those', 3445),\n",
       " ('really', 3407),\n",
       " ('will', 3341),\n",
       " ('probably', 3338),\n",
       " ('something', 3311),\n",
       " ('where', 3234),\n",
       " ('them', 3099),\n",
       " ('which', 3045),\n",
       " ('psa', 3011),\n",
       " ('thing', 2975),\n",
       " ('side', 2919),\n",
       " ('make', 2909),\n",
       " ('d', 2891),\n",
       " ('sure', 2845),\n",
       " ('than', 2825),\n",
       " ('got', 2818),\n",
       " ('did', 2793),\n",
       " ('talk', 2710),\n",
       " ('two', 2650),\n",
       " ('could', 2593),\n",
       " ('low', 2585),\n",
       " ('were', 2568),\n",
       " ('alright', 2557),\n",
       " ('lot', 2515),\n",
       " ('down', 2461),\n",
       " ('let', 2443),\n",
       " ('over', 2420),\n",
       " ('come', 2401),\n",
       " ('bit', 2380),\n",
       " ('way', 2369),\n",
       " ('gleason', 2368),\n",
       " ('said', 2347),\n",
       " ('na', 2326),\n",
       " ('need', 2324),\n",
       " ('who', 2274),\n",
       " ('men', 2264),\n",
       " ('months', 2263),\n",
       " ('done', 2197),\n",
       " ('give', 2172),\n",
       " ('anything', 2150),\n",
       " ('been', 2137),\n",
       " ('weeks', 2134),\n",
       " ('most', 2086),\n",
       " ('much', 2078),\n",
       " ('look', 2029),\n",
       " ('gon', 2016),\n",
       " ('year', 2012),\n",
       " ('long', 1988),\n",
       " ('yes', 1932),\n",
       " ('still', 1931),\n",
       " ('day', 1925),\n",
       " ('doing', 1897),\n",
       " ('may', 1895),\n",
       " ('has', 1859),\n",
       " ('tell', 1843),\n",
       " ('effects', 1838),\n",
       " ('bladder', 1834),\n",
       " ('ah', 1795),\n",
       " ('pretty', 1786),\n",
       " ('blood', 1781),\n",
       " ('actually', 1781),\n",
       " ('dr', 1767),\n",
       " ('through', 1759),\n",
       " ('three', 1757),\n",
       " ('six', 1755),\n",
       " ('put', 1739),\n",
       " ('by', 1722),\n",
       " ('disease', 1711),\n",
       " ('before', 1696),\n",
       " ('does', 1687),\n",
       " ('surveillance', 1682),\n",
       " ('even', 1681),\n",
       " ('too', 1649),\n",
       " ('first', 1631),\n",
       " ('only', 1621),\n",
       " ('better', 1618),\n",
       " ('again', 1610),\n",
       " ('feel', 1609),\n",
       " ('call', 1589),\n",
       " ('usually', 1588),\n",
       " ('high', 1570),\n",
       " ('different', 1561),\n",
       " ('options', 1517),\n",
       " ('having', 1492),\n",
       " ('every', 1488),\n",
       " ('active', 1479),\n",
       " ('us', 1471),\n",
       " ('same', 1464),\n",
       " ('also', 1450),\n",
       " ('these', 1441),\n",
       " ('might', 1439),\n",
       " ('maybe', 1421),\n",
       " ('percent', 1411),\n",
       " ('erections', 1406),\n",
       " ('function', 1393),\n",
       " ('option', 1385),\n",
       " ('problems', 1383),\n",
       " ('didn', 1359),\n",
       " ('why', 1357),\n",
       " ('urinary', 1355),\n",
       " ('aggressive', 1351),\n",
       " ('therapy', 1340),\n",
       " ('their', 1333),\n",
       " ('another', 1326),\n",
       " ('urine', 1323),\n",
       " ('chance', 1317),\n",
       " ('doesn', 1293),\n",
       " ('cause', 1286),\n",
       " ('work', 1285),\n",
       " ('should', 1276),\n",
       " ('into', 1272),\n",
       " ('less', 1272),\n",
       " ('patients', 1268),\n",
       " ('couple', 1261),\n",
       " ('point', 1250),\n",
       " ('she', 1228),\n",
       " ('small', 1228),\n",
       " ('being', 1220),\n",
       " ('our', 1215),\n",
       " ('next', 1213),\n",
       " ('sometimes', 1200),\n",
       " ('treat', 1195),\n",
       " ('questions', 1178),\n",
       " ('ok', 1178),\n",
       " ('five', 1177),\n",
       " ('either', 1159),\n",
       " ('around', 1149),\n",
       " ('score', 1133),\n",
       " ('both', 1132),\n",
       " ('problem', 1117),\n",
       " ('off', 1105),\n",
       " ('everything', 1092),\n",
       " ('yep', 1086),\n",
       " ('sort', 1074),\n",
       " ('big', 1066),\n",
       " ('days', 1065),\n",
       " ('week', 1052),\n",
       " ('getting', 1047),\n",
       " ('able', 1046),\n",
       " ('terms', 1043),\n",
       " ('basically', 1033),\n",
       " ('erectile', 1032),\n",
       " ('catheter', 1017),\n",
       " ('him', 1003),\n",
       " ('his', 994),\n",
       " ('try', 985),\n",
       " ('type', 984),\n",
       " ('number', 980),\n",
       " ('guys', 973),\n",
       " ('far', 972),\n",
       " ('fine', 970),\n",
       " ('decision', 970),\n",
       " ('“', 962),\n",
       " ('never', 962),\n",
       " ('use', 959),\n",
       " ('check', 954),\n",
       " ('ten', 946),\n",
       " ('help', 942),\n",
       " ('stuff', 925),\n",
       " ('intermediate', 924),\n",
       " ('wouldn', 919),\n",
       " ('always', 908),\n",
       " ('today', 895),\n",
       " ('treatments', 895),\n",
       " ('last', 888),\n",
       " ('heart', 880),\n",
       " ('home', 876),\n",
       " ('nothing', 866),\n",
       " ('huh', 863),\n",
       " ('based', 861),\n",
       " ('nerves', 861),\n",
       " ('typically', 859),\n",
       " ('exactly', 853),\n",
       " ('best', 848),\n",
       " ('comes', 846),\n",
       " ('life', 841),\n",
       " ('four', 838),\n",
       " ('higher', 837),\n",
       " ('leakage', 837),\n",
       " ('once', 834),\n",
       " ('called', 833),\n",
       " ('incontinence', 833),\n",
       " ('else', 821),\n",
       " ('great', 817),\n",
       " ('grade', 811),\n",
       " ('biopsies', 806),\n",
       " ('control', 803),\n",
       " ('start', 797),\n",
       " ('part', 794),\n",
       " ('normal', 789),\n",
       " ('area', 781),\n",
       " ('many', 781),\n",
       " ('doctor', 781),\n",
       " ('goes', 778),\n",
       " ('question', 778),\n",
       " ('talking', 777),\n",
       " ('information', 767),\n",
       " ('means', 764),\n",
       " ('thank', 762),\n",
       " ('symptoms', 753),\n",
       " ('age', 753),\n",
       " ('bad', 750),\n",
       " ('patient', 746),\n",
       " ('seeds', 745),\n",
       " ('understand', 743),\n",
       " ('case', 741),\n",
       " ('seven', 738),\n",
       " ('tissue', 738),\n",
       " ('whether', 734),\n",
       " ('away', 731),\n",
       " ('whole', 730),\n",
       " ('wait', 730),\n",
       " ('went', 730),\n",
       " ('recommend', 725),\n",
       " ('exam', 723),\n",
       " ('between', 719),\n",
       " ('procedure', 713),\n",
       " ('least', 709),\n",
       " ('ago', 707),\n",
       " ('whatever', 707),\n",
       " ('end', 702),\n",
       " ('term', 702),\n",
       " ('risks', 700),\n",
       " ('under', 696),\n",
       " ('while', 695),\n",
       " ('keep', 695),\n",
       " ('saying', 691),\n",
       " ('ya', 690),\n",
       " ('ever', 687),\n",
       " ('mmhmm', 687),\n",
       " ('pain', 686),\n",
       " ('nice', 686),\n",
       " ('cores', 685),\n",
       " ('taking', 672),\n",
       " ('rectum', 671),\n",
       " ('old', 669),\n",
       " ('guess', 669),\n",
       " ('looks', 664),\n",
       " ('live', 663),\n",
       " ('cells', 660),\n",
       " ('though', 659),\n",
       " ('took', 658),\n",
       " ('open', 656),\n",
       " ('meet', 654),\n",
       " ('watch', 649),\n",
       " ('robotic', 649),\n",
       " ('looking', 646),\n",
       " ('physician', 642),\n",
       " ('hospital', 642),\n",
       " ('ask', 641),\n",
       " ('already', 640),\n",
       " ('cancers', 634),\n",
       " ('second', 625),\n",
       " ('find', 625),\n",
       " ('decide', 620),\n",
       " ('reason', 619),\n",
       " ('half', 617),\n",
       " ('since', 615),\n",
       " ('likely', 612),\n",
       " ('spread', 611),\n",
       " ('sexual', 611),\n",
       " ('rectal', 607),\n",
       " ('someone', 603),\n",
       " ('dysfunction', 598),\n",
       " ('night', 597),\n",
       " ('lymph', 596),\n",
       " ('remove', 593),\n",
       " ('few', 592),\n",
       " ('urethra', 590),\n",
       " ('am', 587),\n",
       " ('month', 585),\n",
       " ('care', 585),\n",
       " ('positive', 582),\n",
       " ('stay', 581),\n",
       " ('correct', 579),\n",
       " ('times', 577),\n",
       " ('appointment', 574),\n",
       " ('certainly', 573),\n",
       " ('young', 571),\n",
       " ('thought', 571),\n",
       " ('external', 568),\n",
       " ('meaning', 566),\n",
       " ('treated', 566),\n",
       " ('won', 566),\n",
       " ('outside', 565),\n",
       " ('set', 563),\n",
       " ('left', 550),\n",
       " ('family', 549),\n",
       " ('belly', 547),\n",
       " ('read', 546),\n",
       " ('volume', 545),\n",
       " ('enough', 543),\n",
       " ('hard', 542),\n",
       " ('gland', 541),\n",
       " ('worse', 541),\n",
       " ('gets', 541)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.most_common(400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "# max_df = 0.7, min_df = 3,\n",
    "c_vectorizer= CountVectorizer(tokenizer=tokenize, max_df = 0.9, max_features=5000, stop_words = stopwords_comprehensive)\n",
    "cv = c_vectorizer.fit_transform(conversations)\n",
    "cv_feature_names = c_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "no_topics = 35\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "function free sounding spontaneous syndrome tossup scrotum retired differently literally\n",
      "Topic 1:\n",
      "store ton entirely curing information occur culture recurrent friday gain\n",
      "Topic 2:\n",
      "nut judgment coordinator booking child limited cryo age convinced friday\n",
      "Topic 3:\n",
      "surgery urethral yearly cancer continued prostate leaving injury satellite breathing\n",
      "Topic 4:\n",
      "prostate one surgery think hum amount germany intensive sixty achilles\n",
      "Topic 5:\n",
      "prostate cancer surgery radiation well right sample think one see\n",
      "Topic 6:\n",
      "screw hiding gi resort regimen circle expensive skinny inside hundred\n",
      "Topic 7:\n",
      "lowest capsular respiratory nap supervise forecast flash yearly healed stereotactic\n",
      "Topic 8:\n",
      "psa control nursing perfect prob probe crummy dentist deliberate test\n",
      "Topic 9:\n",
      "prostate cancer pressure provider click data going conference tattoo shit\n",
      "Topic 10:\n",
      "deliberate th bill using big decides weaker news steer assessment\n",
      "Topic 11:\n",
      "internet straw stroke ekg neurologist catheter adjacent frustrating testosterone south\n",
      "Topic 12:\n",
      "preserved esophagus united overweight consultation pvr avodart lawyer throat accomplish\n",
      "Topic 13:\n",
      "fell code melt dollar op helped coming chocolate nothing worsened\n",
      "Topic 14:\n",
      "surgery prostate one kind radiation riskbenefit effected erectile risk cancer\n",
      "Topic 15:\n",
      "prostate cancer surgery right radiation mm wa think one well\n",
      "Topic 16:\n",
      "trauma feel bat beacon unusual producing file july email imagine\n",
      "Topic 17:\n",
      "urgency hitting everywhere soda bit live elsewhere kettering road among\n",
      "Topic 18:\n",
      "invades reported radical involved certainty minute hike pleasant million fecal\n",
      "Topic 19:\n",
      "scaffold trouser laser fence mom tap manageable drawn copper trans\n",
      "Topic 20:\n",
      "time cancer sarcoid seek prostate biopsy nevertheless tractor need hydrocele\n",
      "Topic 21:\n",
      "cancer radiation long biopsy year surgery bet psa prostate fresh\n",
      "Topic 22:\n",
      "cancer prostate radiation surgery black biggest youwhat easiest penetration psa\n",
      "Topic 23:\n",
      "prostate evidently inflate ignoring visualization base england accent theand notify\n",
      "Topic 24:\n",
      "develop screwed swollen youngest mmmhmmm washed cancel perineural keloid information\n",
      "Topic 25:\n",
      "unable ho mood maximize struggle diagnosing listed weekly hour bug\n",
      "Topic 26:\n",
      "rather externally later grandkids elbow shrink multi curing wide supervise\n",
      "Topic 27:\n",
      "simply spreading computer picking ahold differentiate news retain mowing explaining\n",
      "Topic 28:\n",
      "believe wire finish ibs apex scrotal teeth culture scoring back\n",
      "Topic 29:\n",
      "cancer radiation prostate thing surgery morbidity one wa spray belief\n",
      "Topic 30:\n",
      "disadvantage cancer nose mitigate kidney well occur body script undergo\n",
      "Topic 31:\n",
      "toward cured stimulate pneumonia estimate auction lived literature proceeding favorable\n",
      "Topic 32:\n",
      "proceed cost carrying run oftentimes colored muscular eradicate definite birthday\n",
      "Topic 33:\n",
      "max divorced goin detection prosthesis ought hook hunch tolerable scaffold\n",
      "Topic 34:\n",
      "washing disrupt backside depth received annoying reassure upwards planned infection\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

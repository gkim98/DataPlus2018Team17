{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process text for entire dataframe\n",
    "- Remove punctuation, parentheses and convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shamelessly borrowed code from 1) https://www2.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html  (tf-idf) 2)https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730 (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc1 = '!\"”#$%&\\'()*+,./:;<>?@[\\\\]^_`{|}~…' # want to replace with ''\n",
    "punc2 = '-=' # want to replace with ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_comprehensive = stopwords.words('english') + ['uhm', 'umm', 'md', 'so', 'pt', 'oth', 'um', 'legend', 'hmm', 'ah', 'na', 'mm' 'hm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parentheses(txt):\n",
    "    txt = re.sub('\\([^)]*\\)\\)','', txt) # remove double parentheses \n",
    "    txt = re.sub(r'\\([^)]*\\)', '', txt) # remove single parentheses \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numerical(txt):\n",
    "    txt = re.sub('[0-9]+', '', txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(txt):\n",
    "    for a in punc1:\n",
    "        txt = txt.replace(a,\"\")\n",
    "    for b in punc2:\n",
    "        txt = txt.replace(b,\" \")\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(txt):\n",
    "    txt = txt.lower()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>Convo_1</th>\n",
       "      <th>Convo_2</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Doctor_1</th>\n",
       "      <th>Doctor_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A003</td>\n",
       "      <td>A003 LEGEND: MD2=Physician PT=Patient MD2: So ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A004</td>\n",
       "      <td>A004 LEGEND: MD2=Physician OTH=Study staff-set...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A014</td>\n",
       "      <td>A014 LEGEND: MD2=Physician PT=Patient MD2: Tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A015</td>\n",
       "      <td>A015_CLEAN LEGEND: MD2=Physician PT=Patient MD...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A016</td>\n",
       "      <td>A016_CLEAN_LOUD LEGEND: MD2=Physician PT: Pati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 patient_id                                            Convo_1  \\\n",
       "0           0       A003  A003 LEGEND: MD2=Physician PT=Patient MD2: So ...   \n",
       "1           1       A004  A004 LEGEND: MD2=Physician OTH=Study staff-set...   \n",
       "2           2       A014  A014 LEGEND: MD2=Physician PT=Patient MD2: Tha...   \n",
       "3           3       A015  A015_CLEAN LEGEND: MD2=Physician PT=Patient MD...   \n",
       "4           4       A016  A016_CLEAN_LOUD LEGEND: MD2=Physician PT: Pati...   \n",
       "\n",
       "  Convo_2 Dataset Doctor_1 Doctor_2  \n",
       "0     NaN      VA        U      NaN  \n",
       "1     NaN      VA        U      NaN  \n",
       "2     NaN      VA        U      NaN  \n",
       "3     NaN      VA        U      NaN  \n",
       "4     NaN      VA        U      NaN  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# clean up each of the convo_1 texts with the processing functions written above\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row['Convo_1']) == False:\n",
    "        row['Convo_1'] = remove_parentheses(row['Convo_1'])\n",
    "        row['Convo_1'] = remove_numerical(row['Convo_1'])\n",
    "        row['Convo_1'] = remove_punc(row['Convo_1'])\n",
    "        row['Convo_1'] = lowercase(row['Convo_1'])\n",
    "        df.set_value(index,'Convo_1', row['Convo_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing, removing stopwords, stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment on one documet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>Convo_1</th>\n",
       "      <th>Convo_2</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Doctor_1</th>\n",
       "      <th>Doctor_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A003</td>\n",
       "      <td>a legend md physician pt patient md so thank y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A004</td>\n",
       "      <td>a legend md physician oth study staff setting ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A014</td>\n",
       "      <td>a legend md physician pt patient md thank you ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A015</td>\n",
       "      <td>aclean legend md physician pt patient md so it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A016</td>\n",
       "      <td>acleanloud legend md physician pt patient md o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VA</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 patient_id                                            Convo_1  \\\n",
       "0           0       A003  a legend md physician pt patient md so thank y...   \n",
       "1           1       A004  a legend md physician oth study staff setting ...   \n",
       "2           2       A014  a legend md physician pt patient md thank you ...   \n",
       "3           3       A015  aclean legend md physician pt patient md so it...   \n",
       "4           4       A016  acleanloud legend md physician pt patient md o...   \n",
       "\n",
       "  Convo_2 Dataset Doctor_1 Doctor_2  \n",
       "0     NaN      VA        U      NaN  \n",
       "1     NaN      VA        U      NaN  \n",
       "2     NaN      VA        U      NaN  \n",
       "3     NaN      VA        U      NaN  \n",
       "4     NaN      VA        U      NaN  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_0 = df['Convo_1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'legend',\n",
       " 'md',\n",
       " 'physician',\n",
       " 'pt',\n",
       " 'patient',\n",
       " 'md',\n",
       " 'so',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'for',\n",
       " 'coming',\n",
       " 'in',\n",
       " 'i',\n",
       " 'know',\n",
       " 'we',\n",
       " 'kinda',\n",
       " 'moved',\n",
       " 'your',\n",
       " 'appointment',\n",
       " 'upbut',\n",
       " 'next',\n",
       " 'week',\n",
       " 'our',\n",
       " 'clinic',\n",
       " 'was',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'overbooked',\n",
       " 'and',\n",
       " 'we',\n",
       " 'didn',\n",
       " 't',\n",
       " 'have',\n",
       " 'staff',\n",
       " 'to',\n",
       " 'bring',\n",
       " 'people',\n",
       " 'in',\n",
       " 'dr',\n",
       " 'pt',\n",
       " 'okay',\n",
       " 'md',\n",
       " 'um',\n",
       " 'so',\n",
       " 'ah',\n",
       " 'we',\n",
       " 'wanted',\n",
       " 'to',\n",
       " 'bring',\n",
       " 'you',\n",
       " 'in',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'your',\n",
       " 'biopsy',\n",
       " 'results',\n",
       " 'um',\n",
       " 'as',\n",
       " 'we',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'expected',\n",
       " 'with',\n",
       " 'your',\n",
       " 'psa',\n",
       " 'being',\n",
       " 'up',\n",
       " 'there',\n",
       " 'was',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sample',\n",
       " 'pt',\n",
       " 'okay',\n",
       " 'md',\n",
       " 'um',\n",
       " 'the',\n",
       " 'ah',\n",
       " 'you',\n",
       " 'know',\n",
       " 'the',\n",
       " 'exam',\n",
       " 'that',\n",
       " 'they',\n",
       " 'did',\n",
       " 'they',\n",
       " 'could',\n",
       " 'feel',\n",
       " 'a',\n",
       " 'little',\n",
       " 'area',\n",
       " 'that',\n",
       " 'felt',\n",
       " 'abnormal',\n",
       " 'on',\n",
       " 'the',\n",
       " 'left',\n",
       " 'side',\n",
       " 'of',\n",
       " 'your',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'and',\n",
       " 'that',\n",
       " 's',\n",
       " 'where',\n",
       " 'the',\n",
       " 'biopsies',\n",
       " 'were',\n",
       " 'positive',\n",
       " 'nd',\n",
       " 'uhh',\n",
       " 'at',\n",
       " 'this',\n",
       " 'point',\n",
       " 'we',\n",
       " 're',\n",
       " 'pt',\n",
       " 'md',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'talk',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'about',\n",
       " 'how',\n",
       " 'we',\n",
       " 'grade',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'what',\n",
       " 'it',\n",
       " 'means',\n",
       " 'what',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'treatment',\n",
       " 'options',\n",
       " 'we',\n",
       " 'have',\n",
       " 'i',\n",
       " 'know',\n",
       " 'that',\n",
       " 'um',\n",
       " 'she',\n",
       " 's',\n",
       " 'probably',\n",
       " 'given',\n",
       " 'you',\n",
       " 'an',\n",
       " 'instruction',\n",
       " 'or',\n",
       " 'at',\n",
       " 'least',\n",
       " 'some',\n",
       " 'handouts',\n",
       " 'that',\n",
       " 'kinda',\n",
       " 'go',\n",
       " 'over',\n",
       " 'you',\n",
       " 'know',\n",
       " 'how',\n",
       " 'we',\n",
       " 'treat',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'and',\n",
       " 'she—if',\n",
       " 'she',\n",
       " 'hasn',\n",
       " 't',\n",
       " 'yet—she',\n",
       " 'll',\n",
       " 'give',\n",
       " 'you',\n",
       " 'the',\n",
       " 'educational',\n",
       " 'today',\n",
       " 'pt',\n",
       " 'md',\n",
       " 'um',\n",
       " 'in',\n",
       " 'general',\n",
       " 'we',\n",
       " 'grade',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'how',\n",
       " 'it',\n",
       " 'looks',\n",
       " 'under',\n",
       " 'the',\n",
       " 'microscope',\n",
       " 'so',\n",
       " 'we',\n",
       " 'lump',\n",
       " 'prostate',\n",
       " 'cancers',\n",
       " 'into',\n",
       " 'risk',\n",
       " 'categories',\n",
       " 'we',\n",
       " 'call',\n",
       " 'them',\n",
       " 'either',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'um',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'or',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'um',\n",
       " 'and',\n",
       " 'we',\n",
       " 'do',\n",
       " 'that',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'psa',\n",
       " 'level',\n",
       " 'and',\n",
       " 'how',\n",
       " 'they',\n",
       " 'look',\n",
       " 'under',\n",
       " 'the',\n",
       " 'microscope',\n",
       " 'in',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'histology',\n",
       " 'pt',\n",
       " 'mmhm',\n",
       " 'md',\n",
       " 'your',\n",
       " 'psa',\n",
       " 'level',\n",
       " 'is',\n",
       " 'a',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'category',\n",
       " 'anything',\n",
       " 'below',\n",
       " 'ten',\n",
       " 'we',\n",
       " 'consider',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'for',\n",
       " 'psa',\n",
       " 'see',\n",
       " 'people',\n",
       " 'who',\n",
       " 'present',\n",
       " 'with',\n",
       " 'psas',\n",
       " 'in',\n",
       " 'the',\n",
       " 's',\n",
       " 'and',\n",
       " 's',\n",
       " 'pt',\n",
       " 'mmhm',\n",
       " 'md',\n",
       " 'they',\n",
       " 're',\n",
       " 'more',\n",
       " 'of',\n",
       " 'a',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'pt',\n",
       " 'and',\n",
       " 'my',\n",
       " 'psa',\n",
       " 'is',\n",
       " 'at',\n",
       " 'md',\n",
       " 'your',\n",
       " 'psa',\n",
       " 'was',\n",
       " 'like',\n",
       " 'around',\n",
       " 'four',\n",
       " 'and',\n",
       " 'a',\n",
       " 'half',\n",
       " 'so',\n",
       " 'it',\n",
       " 'was',\n",
       " 'below',\n",
       " 'five',\n",
       " 'below',\n",
       " 'well',\n",
       " 'well',\n",
       " 'below',\n",
       " 'ten',\n",
       " 'um',\n",
       " 'your',\n",
       " 'um',\n",
       " 'gleason',\n",
       " 'score—which',\n",
       " 'is',\n",
       " 'how',\n",
       " 'it',\n",
       " 'looks',\n",
       " 'under',\n",
       " 'the',\n",
       " 'microscope—they',\n",
       " 'grade',\n",
       " 'them',\n",
       " 'on',\n",
       " 'a',\n",
       " 'scale',\n",
       " 'that',\n",
       " 'runs',\n",
       " 'from',\n",
       " 'basically',\n",
       " 'six',\n",
       " 'to',\n",
       " 'ten',\n",
       " 'um',\n",
       " 'they',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'most',\n",
       " 'common',\n",
       " 'appearance',\n",
       " 'under',\n",
       " 'the',\n",
       " 'microscope',\n",
       " 'the',\n",
       " 'appearances',\n",
       " 'are',\n",
       " 'graded',\n",
       " 'from',\n",
       " 'one',\n",
       " 'to',\n",
       " 'five',\n",
       " 'with',\n",
       " 'five',\n",
       " 'being',\n",
       " 'the',\n",
       " 'most',\n",
       " 'aggressive',\n",
       " 'cancer',\n",
       " 'and',\n",
       " 'one',\n",
       " 'being',\n",
       " 'just',\n",
       " 'a',\n",
       " 'little',\n",
       " 'abnormal',\n",
       " 'not',\n",
       " 'even',\n",
       " 'really',\n",
       " 'cancer',\n",
       " 'cancers',\n",
       " 'are',\n",
       " 'only',\n",
       " 'three',\n",
       " 'four',\n",
       " 'and',\n",
       " 'five',\n",
       " 'and',\n",
       " 'so',\n",
       " 'the',\n",
       " 'gleason',\n",
       " 'score',\n",
       " 'they',\n",
       " 'grade',\n",
       " 'the',\n",
       " 'most',\n",
       " 'common',\n",
       " 'and',\n",
       " 'the',\n",
       " 'second',\n",
       " 'most',\n",
       " 'common',\n",
       " 'appearance',\n",
       " 'on',\n",
       " 'the',\n",
       " 'microscope',\n",
       " 'so',\n",
       " 'the',\n",
       " 'least',\n",
       " 'aggressive',\n",
       " 'cancer',\n",
       " 'you',\n",
       " 'can',\n",
       " 'have',\n",
       " 'is',\n",
       " 'three',\n",
       " 'plus',\n",
       " 'three—or',\n",
       " 'six—as',\n",
       " 'a',\n",
       " 'gleason',\n",
       " 'score',\n",
       " 'the',\n",
       " 'most',\n",
       " 'aggressive',\n",
       " 'you',\n",
       " 'could',\n",
       " 'have',\n",
       " 'would',\n",
       " 'be',\n",
       " 'five',\n",
       " 'plus',\n",
       " 'five',\n",
       " 'or',\n",
       " 'ten',\n",
       " 'so',\n",
       " 'in',\n",
       " 'reality',\n",
       " 'they',\n",
       " 'end',\n",
       " 'up',\n",
       " 'grading',\n",
       " 'things',\n",
       " 'from',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'nine',\n",
       " 'and',\n",
       " 'ten',\n",
       " 'all',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'first',\n",
       " 'number',\n",
       " 'and',\n",
       " 'the',\n",
       " 'second',\n",
       " 'number',\n",
       " 'um',\n",
       " 'yours',\n",
       " 'was',\n",
       " 'three',\n",
       " 'plus',\n",
       " 'four',\n",
       " 'um',\n",
       " 'so',\n",
       " 'that',\n",
       " 'puts',\n",
       " 'you',\n",
       " 'in',\n",
       " 'the',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'category',\n",
       " 'pt',\n",
       " 'yeah',\n",
       " 'med',\n",
       " 'of',\n",
       " 'aggressive',\n",
       " 'so',\n",
       " 'the',\n",
       " 'cells',\n",
       " 'split',\n",
       " 'the',\n",
       " 'cell',\n",
       " 'split',\n",
       " 'rate',\n",
       " 'is',\n",
       " 'than',\n",
       " 'normal',\n",
       " 'okay',\n",
       " 'md',\n",
       " 'and',\n",
       " 'i',\n",
       " 'm',\n",
       " 'recording',\n",
       " 'right',\n",
       " 'now',\n",
       " 'no',\n",
       " 'uhm',\n",
       " 'pt',\n",
       " 'ready',\n",
       " 'set',\n",
       " 'oh',\n",
       " 'md',\n",
       " 'so',\n",
       " 'uhm',\n",
       " 'at',\n",
       " 'this',\n",
       " 'point',\n",
       " 'ah',\n",
       " 'you',\n",
       " 're',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'in',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'how',\n",
       " 'it',\n",
       " 'appears',\n",
       " 'under',\n",
       " 'the',\n",
       " 'microscope',\n",
       " 'you',\n",
       " 're',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'on',\n",
       " 'how',\n",
       " 'it',\n",
       " 'is',\n",
       " 'in',\n",
       " 'psa',\n",
       " 'and',\n",
       " 'so',\n",
       " 'we',\n",
       " 'would',\n",
       " 'c',\n",
       " 'categorize',\n",
       " 'you',\n",
       " 'overall',\n",
       " 'as',\n",
       " 'an',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'patient',\n",
       " 'uhm',\n",
       " 'if',\n",
       " 'you',\n",
       " 'were',\n",
       " 'four',\n",
       " 'plus',\n",
       " 'four',\n",
       " 'or',\n",
       " 'higher',\n",
       " 'we',\n",
       " 'start',\n",
       " 'to',\n",
       " 'look',\n",
       " 'at',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'categories',\n",
       " 'and',\n",
       " 'worry',\n",
       " 'more',\n",
       " 'about',\n",
       " 'spread',\n",
       " 'um',\n",
       " 'at',\n",
       " 'this',\n",
       " 'point',\n",
       " 'spread',\n",
       " 'for',\n",
       " 'you',\n",
       " 'would',\n",
       " 'still',\n",
       " 'be',\n",
       " 'very',\n",
       " 'rare',\n",
       " 'um',\n",
       " 'still',\n",
       " 'probably',\n",
       " 'under',\n",
       " 'or',\n",
       " 'where',\n",
       " 'there',\n",
       " 's',\n",
       " 'starting',\n",
       " 'to',\n",
       " 'be',\n",
       " 'spread',\n",
       " 'outside',\n",
       " 'the',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'into',\n",
       " 'lymph',\n",
       " 'nodes',\n",
       " 'and',\n",
       " 'things',\n",
       " 'like',\n",
       " 'that',\n",
       " 'but',\n",
       " 'it',\n",
       " 'certainly',\n",
       " 'can',\n",
       " 'happen',\n",
       " 'pt',\n",
       " 'yeah',\n",
       " 'it',\n",
       " 'could',\n",
       " 'get',\n",
       " 'into',\n",
       " 'the',\n",
       " 'blood',\n",
       " 'and',\n",
       " 'start',\n",
       " 'travelling',\n",
       " 'md',\n",
       " 'it',\n",
       " 'could',\n",
       " 'start',\n",
       " 'to',\n",
       " 'spread',\n",
       " 'and',\n",
       " 'the',\n",
       " 'most',\n",
       " 'common',\n",
       " 'things',\n",
       " 'that',\n",
       " 'we',\n",
       " 'see',\n",
       " 'spread',\n",
       " 'to',\n",
       " 'are',\n",
       " 'the',\n",
       " 'lymph',\n",
       " 'nodes',\n",
       " 'that',\n",
       " 'are',\n",
       " 'around',\n",
       " 'the',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'and',\n",
       " 'and',\n",
       " 'then',\n",
       " 'further',\n",
       " 'away',\n",
       " 'it',\n",
       " 'starts',\n",
       " 'to',\n",
       " 'spread',\n",
       " 'to',\n",
       " 'places',\n",
       " 'like',\n",
       " 'the',\n",
       " 'bone',\n",
       " 'um',\n",
       " 'but',\n",
       " 'you',\n",
       " 'would',\n",
       " 'be',\n",
       " 'very',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'for',\n",
       " 'having',\n",
       " 'spread',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bone',\n",
       " 'at',\n",
       " 'this',\n",
       " 'point',\n",
       " 'um',\n",
       " 'so',\n",
       " 'treatment',\n",
       " 'options',\n",
       " 'that',\n",
       " 'typically',\n",
       " 'come',\n",
       " 'up',\n",
       " 'for',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'span',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'gambit',\n",
       " 'from',\n",
       " 'minimally',\n",
       " 'invasive',\n",
       " 'things',\n",
       " 'to',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'maximally',\n",
       " 'invasive',\n",
       " 'things',\n",
       " 'that',\n",
       " 'give',\n",
       " 'you',\n",
       " 'the',\n",
       " 'best',\n",
       " 'chance',\n",
       " 'of',\n",
       " 'long',\n",
       " 'term',\n",
       " 'cure',\n",
       " 'in',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'outcomes',\n",
       " 'overall',\n",
       " 'um',\n",
       " 'the',\n",
       " 'survival',\n",
       " 'rate',\n",
       " 'is',\n",
       " 'very',\n",
       " 'good',\n",
       " 'ten',\n",
       " 'fifteen',\n",
       " 'plus',\n",
       " 'years',\n",
       " 'down',\n",
       " 'the',\n",
       " 'road',\n",
       " 'um',\n",
       " 'in',\n",
       " 'fact',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 's',\n",
       " 'so',\n",
       " 'slow',\n",
       " 'growing',\n",
       " 'that',\n",
       " 'we',\n",
       " 'don',\n",
       " 't',\n",
       " 'even',\n",
       " 'really',\n",
       " 'recommend',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'it',\n",
       " 'as',\n",
       " 'people',\n",
       " 'get',\n",
       " 'older',\n",
       " 'and',\n",
       " 'older',\n",
       " 'because',\n",
       " 'the',\n",
       " 'chance',\n",
       " 'of',\n",
       " 'you',\n",
       " 'dying',\n",
       " 'from',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'is',\n",
       " 'low',\n",
       " 'enough',\n",
       " 'that',\n",
       " 'your',\n",
       " 'heart',\n",
       " 's',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'have',\n",
       " 'a',\n",
       " 'problem',\n",
       " 'or',\n",
       " 'you',\n",
       " 're',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'have',\n",
       " 'diabetes',\n",
       " 'or',\n",
       " 'something',\n",
       " 'like',\n",
       " 'that',\n",
       " 'now',\n",
       " 'you',\n",
       " 'appear',\n",
       " 'very',\n",
       " 'healthy',\n",
       " 'so',\n",
       " 'i',\n",
       " 'i',\n",
       " 'don',\n",
       " 't',\n",
       " 'think',\n",
       " 'that',\n",
       " 'that',\n",
       " 's',\n",
       " 'the',\n",
       " 'issue',\n",
       " 'for',\n",
       " 'you',\n",
       " 'and',\n",
       " 'you',\n",
       " 're',\n",
       " 'young',\n",
       " 'enough',\n",
       " 'that',\n",
       " 'we',\n",
       " 'need',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'treatment',\n",
       " 'so',\n",
       " 'that',\n",
       " 'kinda',\n",
       " 'rules',\n",
       " 'out',\n",
       " 'the',\n",
       " 'ya',\n",
       " 'know',\n",
       " 'the',\n",
       " 'typical',\n",
       " 'you',\n",
       " 'know',\n",
       " 'way',\n",
       " 'that',\n",
       " 'we',\n",
       " 'would',\n",
       " 'think',\n",
       " 'about',\n",
       " 'doing',\n",
       " 'it',\n",
       " 'in',\n",
       " 'someone',\n",
       " 'who',\n",
       " 's',\n",
       " 'almost',\n",
       " 'years',\n",
       " 'old',\n",
       " 'which',\n",
       " 'is',\n",
       " 'we',\n",
       " 'don',\n",
       " 't',\n",
       " 'even',\n",
       " 'really',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'know',\n",
       " 'about',\n",
       " 'it',\n",
       " 'we',\n",
       " 'don',\n",
       " 't',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'treat',\n",
       " 'it',\n",
       " 'because',\n",
       " 'the',\n",
       " 'treatment',\n",
       " 's',\n",
       " 'often',\n",
       " 'worse',\n",
       " 'than',\n",
       " 'just',\n",
       " 'letting',\n",
       " 'it',\n",
       " 'go',\n",
       " 'cuz',\n",
       " 'it',\n",
       " 'grows',\n",
       " 'so',\n",
       " 'slowly',\n",
       " 'pt',\n",
       " 'yeah',\n",
       " 'the',\n",
       " 'cure',\n",
       " 's',\n",
       " 'worse',\n",
       " 'than',\n",
       " 'the',\n",
       " 'disease',\n",
       " 'okay',\n",
       " 'md',\n",
       " 'so',\n",
       " 'for',\n",
       " 'you',\n",
       " 'there',\n",
       " 'is',\n",
       " 'a',\n",
       " 'treatment',\n",
       " 'that',\n",
       " 'would',\n",
       " 'be',\n",
       " 'similar',\n",
       " 'to',\n",
       " 'that',\n",
       " 'and',\n",
       " 'it',\n",
       " 's',\n",
       " 'called',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'um',\n",
       " 'the',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'we',\n",
       " 'uh',\n",
       " 'used',\n",
       " 'to',\n",
       " 'do',\n",
       " 'for',\n",
       " 'older',\n",
       " 'people',\n",
       " 'is',\n",
       " 'just',\n",
       " 'watching',\n",
       " 'and',\n",
       " 'waiting',\n",
       " 'until',\n",
       " 'things',\n",
       " 'got',\n",
       " 'worse',\n",
       " 'and',\n",
       " 'then',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'fix',\n",
       " 'it',\n",
       " 'is',\n",
       " 'watchful',\n",
       " 'waiting',\n",
       " 'and',\n",
       " 'that',\n",
       " 's',\n",
       " 'not',\n",
       " 'really',\n",
       " 'what',\n",
       " 'we',\n",
       " 'focus',\n",
       " 'on',\n",
       " 'anymore',\n",
       " 'we',\n",
       " 've',\n",
       " 'moved',\n",
       " 'more',\n",
       " 'towards',\n",
       " 'what',\n",
       " 'we',\n",
       " 'call',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'which',\n",
       " 'is',\n",
       " 'where',\n",
       " 'we',\n",
       " 'follow',\n",
       " 'you',\n",
       " 'we',\n",
       " 'check',\n",
       " 'psas',\n",
       " 'we',\n",
       " 'do',\n",
       " 'repeat',\n",
       " 'biopsies',\n",
       " 'we',\n",
       " 'do',\n",
       " 'another',\n",
       " 'biopsy',\n",
       " 'at',\n",
       " 'say',\n",
       " 'six',\n",
       " 'months',\n",
       " 'just',\n",
       " 'to',\n",
       " 'check',\n",
       " 'and',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'there',\n",
       " 'was',\n",
       " 'no',\n",
       " 'change',\n",
       " 'and',\n",
       " 'then',\n",
       " 'we',\n",
       " 'd',\n",
       " 're',\n",
       " 'biopsy',\n",
       " 'year',\n",
       " 'after',\n",
       " 'year',\n",
       " 'i',\n",
       " 'm',\n",
       " 'not',\n",
       " 'saying',\n",
       " 'this',\n",
       " 'is',\n",
       " 'what',\n",
       " ...]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(convo_0)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['physician',\n",
       " 'patient',\n",
       " 'thank',\n",
       " 'coming',\n",
       " 'know',\n",
       " 'kinda',\n",
       " 'moved',\n",
       " 'appointment',\n",
       " 'upbut',\n",
       " 'next',\n",
       " 'week',\n",
       " 'clinic',\n",
       " 'kind',\n",
       " 'overbooked',\n",
       " 'staff',\n",
       " 'bring',\n",
       " 'people',\n",
       " 'dr',\n",
       " 'okay',\n",
       " 'ah',\n",
       " 'wanted',\n",
       " 'bring',\n",
       " 'talk',\n",
       " 'biopsy',\n",
       " 'results',\n",
       " 'kind',\n",
       " 'expected',\n",
       " 'psa',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'sample',\n",
       " 'okay',\n",
       " 'ah',\n",
       " 'know',\n",
       " 'exam',\n",
       " 'could',\n",
       " 'feel',\n",
       " 'little',\n",
       " 'area',\n",
       " 'felt',\n",
       " 'abnormal',\n",
       " 'left',\n",
       " 'side',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'biopsies',\n",
       " 'positive',\n",
       " 'nd',\n",
       " 'uhh',\n",
       " 'point',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'talk',\n",
       " 'kind',\n",
       " 'grade',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'means',\n",
       " 'kind',\n",
       " 'treatment',\n",
       " 'options',\n",
       " 'know',\n",
       " 'probably',\n",
       " 'given',\n",
       " 'instruction',\n",
       " 'least',\n",
       " 'handouts',\n",
       " 'kinda',\n",
       " 'go',\n",
       " 'know',\n",
       " 'treat',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'she—if',\n",
       " 'yet—she',\n",
       " 'give',\n",
       " 'educational',\n",
       " 'today',\n",
       " 'general',\n",
       " 'grade',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'looks',\n",
       " 'microscope',\n",
       " 'lump',\n",
       " 'prostate',\n",
       " 'cancers',\n",
       " 'risk',\n",
       " 'categories',\n",
       " 'call',\n",
       " 'either',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'based',\n",
       " 'psa',\n",
       " 'level',\n",
       " 'look',\n",
       " 'microscope',\n",
       " 'terms',\n",
       " 'histology',\n",
       " 'mmhm',\n",
       " 'psa',\n",
       " 'level',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'category',\n",
       " 'anything',\n",
       " 'ten',\n",
       " 'consider',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'psa',\n",
       " 'see',\n",
       " 'people',\n",
       " 'present',\n",
       " 'psas',\n",
       " 'mmhm',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'psa',\n",
       " 'psa',\n",
       " 'like',\n",
       " 'around',\n",
       " 'four',\n",
       " 'half',\n",
       " 'five',\n",
       " 'well',\n",
       " 'well',\n",
       " 'ten',\n",
       " 'gleason',\n",
       " 'score—which',\n",
       " 'looks',\n",
       " 'microscope—they',\n",
       " 'grade',\n",
       " 'scale',\n",
       " 'runs',\n",
       " 'basically',\n",
       " 'six',\n",
       " 'ten',\n",
       " 'look',\n",
       " 'common',\n",
       " 'appearance',\n",
       " 'microscope',\n",
       " 'appearances',\n",
       " 'graded',\n",
       " 'one',\n",
       " 'five',\n",
       " 'five',\n",
       " 'aggressive',\n",
       " 'cancer',\n",
       " 'one',\n",
       " 'little',\n",
       " 'abnormal',\n",
       " 'even',\n",
       " 'really',\n",
       " 'cancer',\n",
       " 'cancers',\n",
       " 'three',\n",
       " 'four',\n",
       " 'five',\n",
       " 'gleason',\n",
       " 'score',\n",
       " 'grade',\n",
       " 'common',\n",
       " 'second',\n",
       " 'common',\n",
       " 'appearance',\n",
       " 'microscope',\n",
       " 'least',\n",
       " 'aggressive',\n",
       " 'cancer',\n",
       " 'three',\n",
       " 'plus',\n",
       " 'three—or',\n",
       " 'six—as',\n",
       " 'gleason',\n",
       " 'score',\n",
       " 'aggressive',\n",
       " 'could',\n",
       " 'would',\n",
       " 'five',\n",
       " 'plus',\n",
       " 'five',\n",
       " 'ten',\n",
       " 'reality',\n",
       " 'end',\n",
       " 'grading',\n",
       " 'things',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'based',\n",
       " 'first',\n",
       " 'number',\n",
       " 'second',\n",
       " 'number',\n",
       " 'three',\n",
       " 'plus',\n",
       " 'four',\n",
       " 'puts',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'category',\n",
       " 'yeah',\n",
       " 'med',\n",
       " 'aggressive',\n",
       " 'cells',\n",
       " 'split',\n",
       " 'cell',\n",
       " 'split',\n",
       " 'rate',\n",
       " 'normal',\n",
       " 'okay',\n",
       " 'recording',\n",
       " 'right',\n",
       " 'ready',\n",
       " 'set',\n",
       " 'oh',\n",
       " 'point',\n",
       " 'ah',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'terms',\n",
       " 'appears',\n",
       " 'microscope',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'psa',\n",
       " 'would',\n",
       " 'c',\n",
       " 'categorize',\n",
       " 'overall',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'patient',\n",
       " 'four',\n",
       " 'plus',\n",
       " 'four',\n",
       " 'higher',\n",
       " 'start',\n",
       " 'look',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'categories',\n",
       " 'worry',\n",
       " 'spread',\n",
       " 'point',\n",
       " 'spread',\n",
       " 'would',\n",
       " 'still',\n",
       " 'rare',\n",
       " 'still',\n",
       " 'probably',\n",
       " 'starting',\n",
       " 'spread',\n",
       " 'outside',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'lymph',\n",
       " 'nodes',\n",
       " 'things',\n",
       " 'like',\n",
       " 'certainly',\n",
       " 'happen',\n",
       " 'yeah',\n",
       " 'could',\n",
       " 'get',\n",
       " 'blood',\n",
       " 'start',\n",
       " 'travelling',\n",
       " 'could',\n",
       " 'start',\n",
       " 'spread',\n",
       " 'common',\n",
       " 'things',\n",
       " 'see',\n",
       " 'spread',\n",
       " 'lymph',\n",
       " 'nodes',\n",
       " 'around',\n",
       " 'prostate',\n",
       " 'gland',\n",
       " 'away',\n",
       " 'starts',\n",
       " 'spread',\n",
       " 'places',\n",
       " 'like',\n",
       " 'bone',\n",
       " 'would',\n",
       " 'low',\n",
       " 'risk',\n",
       " 'spread',\n",
       " 'bone',\n",
       " 'point',\n",
       " 'treatment',\n",
       " 'options',\n",
       " 'typically',\n",
       " 'come',\n",
       " 'intermediate',\n",
       " 'risk',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'span',\n",
       " 'whole',\n",
       " 'gambit',\n",
       " 'minimally',\n",
       " 'invasive',\n",
       " 'things',\n",
       " 'kind',\n",
       " 'maximally',\n",
       " 'invasive',\n",
       " 'things',\n",
       " 'give',\n",
       " 'best',\n",
       " 'chance',\n",
       " 'long',\n",
       " 'term',\n",
       " 'cure',\n",
       " 'terms',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'outcomes',\n",
       " 'overall',\n",
       " 'survival',\n",
       " 'rate',\n",
       " 'good',\n",
       " 'ten',\n",
       " 'fifteen',\n",
       " 'plus',\n",
       " 'years',\n",
       " 'road',\n",
       " 'fact',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'slow',\n",
       " 'growing',\n",
       " 'even',\n",
       " 'really',\n",
       " 'recommend',\n",
       " 'looking',\n",
       " 'people',\n",
       " 'get',\n",
       " 'older',\n",
       " 'older',\n",
       " 'chance',\n",
       " 'dying',\n",
       " 'prostate',\n",
       " 'cancer',\n",
       " 'low',\n",
       " 'enough',\n",
       " 'heart',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'problem',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'diabetes',\n",
       " 'something',\n",
       " 'like',\n",
       " 'appear',\n",
       " 'healthy',\n",
       " 'think',\n",
       " 'issue',\n",
       " 'young',\n",
       " 'enough',\n",
       " 'need',\n",
       " 'talk',\n",
       " 'treatment',\n",
       " 'kinda',\n",
       " 'rules',\n",
       " 'ya',\n",
       " 'know',\n",
       " 'typical',\n",
       " 'know',\n",
       " 'way',\n",
       " 'would',\n",
       " 'think',\n",
       " 'someone',\n",
       " 'almost',\n",
       " 'years',\n",
       " 'old',\n",
       " 'even',\n",
       " 'really',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'know',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'treat',\n",
       " 'treatment',\n",
       " 'often',\n",
       " 'worse',\n",
       " 'letting',\n",
       " 'go',\n",
       " 'cuz',\n",
       " 'grows',\n",
       " 'slowly',\n",
       " 'yeah',\n",
       " 'cure',\n",
       " 'worse',\n",
       " 'disease',\n",
       " 'okay',\n",
       " 'treatment',\n",
       " 'would',\n",
       " 'similar',\n",
       " 'called',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'thing',\n",
       " 'uh',\n",
       " 'used',\n",
       " 'older',\n",
       " 'people',\n",
       " 'watching',\n",
       " 'waiting',\n",
       " 'things',\n",
       " 'got',\n",
       " 'worse',\n",
       " 'trying',\n",
       " 'fix',\n",
       " 'watchful',\n",
       " 'waiting',\n",
       " 'really',\n",
       " 'focus',\n",
       " 'anymore',\n",
       " 'moved',\n",
       " 'towards',\n",
       " 'call',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'follow',\n",
       " 'check',\n",
       " 'psas',\n",
       " 'repeat',\n",
       " 'biopsies',\n",
       " 'another',\n",
       " 'biopsy',\n",
       " 'say',\n",
       " 'six',\n",
       " 'months',\n",
       " 'check',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'change',\n",
       " 'biopsy',\n",
       " 'year',\n",
       " 'year',\n",
       " 'saying',\n",
       " 'recommend',\n",
       " 'going',\n",
       " 'talk',\n",
       " 'wanted',\n",
       " 'know',\n",
       " 'options',\n",
       " 'may',\n",
       " 'see',\n",
       " 'computer',\n",
       " 'internet',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'designed',\n",
       " 'delay',\n",
       " 'treating',\n",
       " 'cancer',\n",
       " 'live',\n",
       " 'live',\n",
       " 'normally',\n",
       " 'right',\n",
       " 'normal',\n",
       " 'sexual',\n",
       " 'function',\n",
       " 'normal',\n",
       " 'erectile',\n",
       " 'function',\n",
       " 'normal',\n",
       " 'urinary',\n",
       " 'control',\n",
       " 'things',\n",
       " 'cancer',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'getting',\n",
       " 'aggressive',\n",
       " 'enough',\n",
       " 'need',\n",
       " 'something',\n",
       " 'even',\n",
       " 'really',\n",
       " 'qualify',\n",
       " 'biopsy',\n",
       " 'results',\n",
       " 'enough',\n",
       " 'cores',\n",
       " 'four',\n",
       " 'cores',\n",
       " 'cancer',\n",
       " 'four',\n",
       " 'twelve',\n",
       " 'samples',\n",
       " 'took',\n",
       " 'cancer',\n",
       " 'enough',\n",
       " 'cancer',\n",
       " 'core',\n",
       " 'like',\n",
       " 'core',\n",
       " 'long',\n",
       " 'talking',\n",
       " 'half',\n",
       " 'core',\n",
       " 'cancer',\n",
       " 'means',\n",
       " 'little',\n",
       " 'more—higher',\n",
       " 'risk',\n",
       " 'someone',\n",
       " 'would',\n",
       " 'typically',\n",
       " 'put',\n",
       " 'active',\n",
       " 'surveillance',\n",
       " 'know',\n",
       " 'particularly',\n",
       " 'think',\n",
       " 'best',\n",
       " 'option',\n",
       " 'best',\n",
       " 'options',\n",
       " 'would',\n",
       " 'one',\n",
       " 'two',\n",
       " 'forms',\n",
       " 'active',\n",
       " 'treatment',\n",
       " 'offer',\n",
       " 'va',\n",
       " 'surgery',\n",
       " 'remove',\n",
       " 'prostate',\n",
       " 'radiation',\n",
       " 'therapy',\n",
       " 'radiation',\n",
       " 'therapy',\n",
       " 'external',\n",
       " 'beam',\n",
       " 'radiation',\n",
       " 'therapy',\n",
       " 'imrt',\n",
       " 'proton',\n",
       " 'radiation',\n",
       " 'proton',\n",
       " 'radiation',\n",
       " 'proton',\n",
       " 'four',\n",
       " 'five',\n",
       " 'centers',\n",
       " 'u',\n",
       " 'know',\n",
       " 'ss',\n",
       " 'okay',\n",
       " 'go',\n",
       " 'ahead',\n",
       " 'gon',\n",
       " 'na',\n",
       " 'offend',\n",
       " 'anyone',\n",
       " 'va',\n",
       " 'system',\n",
       " 'ahh',\n",
       " 'seek',\n",
       " 'proton',\n",
       " 'radiation',\n",
       " 'dr',\n",
       " 'grants',\n",
       " 'er',\n",
       " 'anything',\n",
       " 'va',\n",
       " 'would',\n",
       " 'provide',\n",
       " 'know',\n",
       " 'situation']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = [w for w in tokens if not w in stopwords_comprehensive]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cancer', 17), ('risk', 15), ('prostate', 13), ('know', 11), ('would', 9), ('four', 8), ('psa', 7), ('five', 7), ('things', 7), ('spread', 7), ('na', 6), ('treatment', 6), ('low', 6), ('ten', 6), ('like', 6), ('radiation', 6), ('kind', 5), ('okay', 5), ('microscope', 5), ('intermediate', 5), ('aggressive', 5), ('really', 5), ('plus', 5), ('enough', 5), ('active', 5), ('people', 4), ('talk', 4), ('biopsy', 4), ('could', 4), ('point', 4), ('gon', 4), ('grade', 4), ('options', 4), ('common', 4), ('even', 4), ('normal', 4), ('surveillance', 4), ('proton', 4), ('kinda', 3), ('ah', 3), ('little', 3), ('gland', 3), ('go', 3), ('looks', 3), ('high', 3), ('look', 3), ('terms', 3), ('see', 3), ('gleason', 3), ('six', 3), ('one', 3), ('three', 3), ('yeah', 3), ('start', 3), ('best', 3), ('older', 3), ('think', 3), ('worse', 3), ('core', 3), ('va', 3), ('therapy', 3), ('patient', 2), ('moved', 2), ('bring', 2), ('dr', 2), ('wanted', 2), ('results', 2), ('abnormal', 2), ('biopsies', 2), ('means', 2), ('probably', 2), ('least', 2), ('treat', 2), ('give', 2), ('cancers', 2), ('categories', 2), ('call', 2), ('based', 2), ('level', 2), ('mmhm', 2), ('category', 2), ('anything', 2), ('psas', 2), ('around', 2), ('half', 2), ('well', 2), ('appearance', 2), ('score', 2), ('second', 2), ('number', 2), ('split', 2), ('rate', 2), ('right', 2), ('overall', 2), ('still', 2), ('lymph', 2), ('nodes', 2), ('get', 2), ('bone', 2), ('typically', 2)]\n"
     ]
    }
   ],
   "source": [
    "# check most common words see if there is anything we should add to stopwords list\n",
    "count = Counter(filtered)\n",
    "print(count.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cancer', 19), ('risk', 15), ('prostat', 13), ('know', 11), ('psa', 9), ('would', 9), ('four', 8), ('thing', 8), ('look', 7), ('five', 7), ('spread', 7), ('biopsi', 6), ('na', 6), ('grade', 6), ('treatment', 6), ('low', 6), ('ten', 6), ('like', 6), ('radiat', 6), ('kind', 5), ('okay', 5), ('talk', 5), ('option', 5), ('microscop', 5), ('intermedi', 5), ('appear', 5), ('aggress', 5), ('realli', 5), ('plu', 5), ('normal', 5), ('start', 5), ('enough', 5), ('activ', 5), ('core', 5), ('peopl', 4), ('could', 4), ('point', 4), ('gon', 4), ('go', 4), ('categori', 4), ('term', 4), ('common', 4), ('even', 4), ('year', 4), ('surveil', 4), ('proton', 4), ('kinda', 3), ('ah', 3), ('littl', 3), ('gland', 3), ('treat', 3), ('call', 3), ('high', 3), ('see', 3), ('gleason', 3), ('six', 3), ('one', 3), ('three', 3), ('yeah', 3), ('get', 3), ('typic', 3), ('best', 3), ('older', 3), ('think', 3), ('wors', 3), ('va', 3), ('therapi', 3), ('patient', 2), ('come', 2), ('move', 2), ('bring', 2), ('dr', 2), ('want', 2), ('result', 2), ('sampl', 2), ('abnorm', 2), ('mean', 2), ('probabl', 2), ('least', 2), ('give', 2), ('base', 2), ('level', 2), ('mmhm', 2), ('anyth', 2), ('around', 2), ('half', 2), ('well', 2), ('score', 2), ('second', 2), ('number', 2), ('put', 2), ('cell', 2), ('split', 2), ('rate', 2), ('right', 2), ('overal', 2), ('still', 2), ('lymph', 2), ('node', 2), ('bone', 2)]\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed = stem_tokens(filtered, stemmer)\n",
    "count = Counter(stemmed)\n",
    "print(count.most_common(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to process entire conversation 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nona = df.dropna(subset=['Convo_1'])\n",
    "conversations = df_nona['Convo_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stopwords_comprehensive = stopwords.words('english') + ['uhm', 'md3', 'md2', 'md', 'so', 'pt', 'oth', 'um', 'legend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # filtered = [w for w in tokens if not w in stopwords_comprehensive]\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize, max_df = 0.7, min_df = 3, max_features=5000, stop_words = stopwords_comprehensive)\n",
    "tfs = tfidf.fit_transform(conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaah',\n",
       " 'aah',\n",
       " 'ab',\n",
       " 'abat',\n",
       " 'abdomen',\n",
       " 'abdomin',\n",
       " 'abil',\n",
       " 'ablat',\n",
       " 'abnorm',\n",
       " 'about…',\n",
       " 'about…i',\n",
       " 'about…y',\n",
       " 'abov',\n",
       " 'abrupt',\n",
       " 'abscess',\n",
       " 'absenc',\n",
       " 'absolut',\n",
       " 'absorb',\n",
       " 'abus',\n",
       " 'abut',\n",
       " 'ac',\n",
       " 'academ',\n",
       " 'acceler',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accid',\n",
       " 'accommod',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accru',\n",
       " 'accumul',\n",
       " 'accur',\n",
       " 'accuraci',\n",
       " 'ach',\n",
       " 'achi',\n",
       " 'achiev',\n",
       " 'achil',\n",
       " 'acid',\n",
       " 'aclean',\n",
       " 'acleanloud',\n",
       " 'acquaint',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'actor',\n",
       " 'actually…',\n",
       " 'acut',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adenocarcinoma',\n",
       " 'adenoid',\n",
       " 'adequ',\n",
       " 'adher',\n",
       " 'adjac',\n",
       " 'adjunct',\n",
       " 'adjust',\n",
       " 'adjuv',\n",
       " 'administ',\n",
       " 'administr',\n",
       " 'admir',\n",
       " 'admit',\n",
       " 'admittedli',\n",
       " 'adopt',\n",
       " 'adult',\n",
       " 'advair',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'advers',\n",
       " 'advertis',\n",
       " 'advic',\n",
       " 'advil',\n",
       " 'advis',\n",
       " 'advoc',\n",
       " 'affect',\n",
       " 'affili',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'african',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'afterword',\n",
       " 'after…',\n",
       " 'after…aft',\n",
       " 'again…',\n",
       " 'agent',\n",
       " 'aggrav',\n",
       " 'aggressive…',\n",
       " 'ago',\n",
       " 'ago…',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahh…',\n",
       " 'ahold',\n",
       " 'ah…',\n",
       " 'ah…you',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airlin',\n",
       " 'airplan',\n",
       " 'airport',\n",
       " 'alabama',\n",
       " 'alarm',\n",
       " 'alaska',\n",
       " 'albuterol',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'algorithm',\n",
       " 'align',\n",
       " 'aliv',\n",
       " 'allerg',\n",
       " 'allergi',\n",
       " 'allevi',\n",
       " 'allow',\n",
       " 'all…',\n",
       " 'almost',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alongsid',\n",
       " 'alot',\n",
       " 'alpha',\n",
       " 'alreadi',\n",
       " 'already…',\n",
       " 'alrighti',\n",
       " 'alright…',\n",
       " 'also…',\n",
       " 'alter',\n",
       " 'altern',\n",
       " 'although',\n",
       " 'altogeth',\n",
       " 'alzheim',\n",
       " 'amaz',\n",
       " 'amazingli',\n",
       " 'ambul',\n",
       " 'ambulatori',\n",
       " 'amen',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amlodipin',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'am…',\n",
       " 'anal',\n",
       " 'analog',\n",
       " 'analysi',\n",
       " 'analyz',\n",
       " 'anastomosi',\n",
       " 'anatom',\n",
       " 'anatomi',\n",
       " 'andor',\n",
       " 'androgen',\n",
       " 'and…',\n",
       " 'and…and',\n",
       " 'and…but',\n",
       " 'and…i',\n",
       " 'anecdot',\n",
       " 'anesthesia',\n",
       " 'anesthesiologist',\n",
       " 'anesthet',\n",
       " 'aneur',\n",
       " 'angina',\n",
       " 'angioplasti',\n",
       " 'angl',\n",
       " 'angri',\n",
       " 'anim',\n",
       " 'ankl',\n",
       " 'annoy',\n",
       " 'annual',\n",
       " 'another…',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'antenna',\n",
       " 'anterior',\n",
       " 'anti',\n",
       " 'antibiot',\n",
       " 'anticip',\n",
       " 'anticoagul',\n",
       " 'antidepress',\n",
       " 'antigen',\n",
       " 'anu',\n",
       " 'anxieti',\n",
       " 'anxiou',\n",
       " 'anybodi',\n",
       " 'anyhow',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anything…',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'anyway…',\n",
       " 'anywher',\n",
       " 'any…',\n",
       " 'any…ani',\n",
       " 'an…',\n",
       " 'aorta',\n",
       " 'aortic',\n",
       " 'apart',\n",
       " 'apex',\n",
       " 'apnea',\n",
       " 'apolog',\n",
       " 'appar',\n",
       " 'apparatu',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'append',\n",
       " 'appendectomi',\n",
       " 'appendix',\n",
       " 'appetit',\n",
       " 'appl',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'approxim',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'arbitrari',\n",
       " 'architectur',\n",
       " 'area',\n",
       " 'area…',\n",
       " 'are…',\n",
       " 'are…ther',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'aris',\n",
       " 'arm',\n",
       " 'armi',\n",
       " 'armpit',\n",
       " 'arrang',\n",
       " 'arriv',\n",
       " 'art',\n",
       " 'arteri',\n",
       " 'arthriti',\n",
       " 'arthroscop',\n",
       " 'articl',\n",
       " 'articul',\n",
       " 'artifici',\n",
       " 'artist',\n",
       " 'asap',\n",
       " 'asbesto',\n",
       " 'asian',\n",
       " 'asid',\n",
       " 'ask…',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspirin',\n",
       " 'ass',\n",
       " 'assess',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'assum',\n",
       " 'assumpt',\n",
       " 'assur',\n",
       " 'asthma',\n",
       " 'asymptomat',\n",
       " 'as…',\n",
       " 'as…a',\n",
       " 'ate',\n",
       " 'athlet',\n",
       " 'atrial',\n",
       " 'atrophi',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attest',\n",
       " 'attitud',\n",
       " 'attract',\n",
       " 'attribut',\n",
       " 'atyp',\n",
       " 'at…',\n",
       " 'aua',\n",
       " 'augment',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'author',\n",
       " 'auto',\n",
       " 'automat',\n",
       " 'autopsi',\n",
       " 'avail',\n",
       " 'avenu',\n",
       " 'averag',\n",
       " 'avodart',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'awak',\n",
       " 'awar',\n",
       " 'awesom',\n",
       " 'awhil',\n",
       " 'aww',\n",
       " 'a…',\n",
       " 'a…a',\n",
       " 'a…an',\n",
       " 'a…and',\n",
       " 'a…h',\n",
       " 'a…i',\n",
       " 'a…in',\n",
       " 'a…it',\n",
       " 'a…that',\n",
       " 'a…ther',\n",
       " 'a…you',\n",
       " 'b',\n",
       " 'babi',\n",
       " 'background',\n",
       " 'backsid',\n",
       " 'backup',\n",
       " 'backward',\n",
       " 'back…',\n",
       " 'bacteria',\n",
       " 'bactrim',\n",
       " 'bad',\n",
       " 'badli',\n",
       " 'bag',\n",
       " 'balanc',\n",
       " 'ball',\n",
       " 'balloon',\n",
       " 'ballpark',\n",
       " 'bam',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'barber',\n",
       " 'bare',\n",
       " 'barg',\n",
       " 'bariatr',\n",
       " 'baromet',\n",
       " 'basal',\n",
       " 'base',\n",
       " 'basebal',\n",
       " 'baselin',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'basically…',\n",
       " 'bat',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batteri',\n",
       " 'battl',\n",
       " 'bay',\n",
       " 'bb',\n",
       " 'beacon',\n",
       " 'bead',\n",
       " 'beam',\n",
       " 'bear',\n",
       " 'bearer',\n",
       " 'beat',\n",
       " 'beauti',\n",
       " 'becam',\n",
       " 'because…',\n",
       " 'becom',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'bedsid',\n",
       " 'bedtim',\n",
       " 'been…',\n",
       " 'beer',\n",
       " 'beforehand',\n",
       " 'before…',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'begun',\n",
       " 'behav',\n",
       " 'behavior',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being…',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'bell',\n",
       " 'belli',\n",
       " 'bellybutton',\n",
       " 'belong',\n",
       " 'belt',\n",
       " 'bench',\n",
       " 'bend',\n",
       " 'beneath',\n",
       " 'benefici',\n",
       " 'benefit',\n",
       " 'benign',\n",
       " 'besid',\n",
       " 'bet',\n",
       " 'betcha',\n",
       " 'between…',\n",
       " 'beyond',\n",
       " 'be…',\n",
       " 'be…i',\n",
       " 'be…it',\n",
       " 'be…would',\n",
       " 'be…you',\n",
       " 'bi',\n",
       " 'bia',\n",
       " 'bias',\n",
       " 'bicycl',\n",
       " 'bid',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bilater',\n",
       " 'bill',\n",
       " 'bind',\n",
       " 'bio',\n",
       " 'biochem',\n",
       " 'biolog',\n",
       " 'biop',\n",
       " 'biopsy…',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bite',\n",
       " 'bitti',\n",
       " 'bit…',\n",
       " 'black',\n",
       " 'bladder…',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'bled',\n",
       " 'bleed',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'bloat',\n",
       " 'block',\n",
       " 'blockag',\n",
       " 'blocker',\n",
       " 'bloodi',\n",
       " 'blood…',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'blur',\n",
       " 'bmi',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bodi',\n",
       " 'boil',\n",
       " 'bomb',\n",
       " 'bone',\n",
       " 'book',\n",
       " 'booklet',\n",
       " 'boom',\n",
       " 'boost',\n",
       " 'border',\n",
       " 'borderlin',\n",
       " 'bore',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'boss',\n",
       " 'bother',\n",
       " 'bothersom',\n",
       " 'both…',\n",
       " 'bottl',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bounc',\n",
       " 'boundari',\n",
       " 'bout',\n",
       " 'bowel',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'bph',\n",
       " 'brace',\n",
       " 'brachi',\n",
       " 'brachytherapi',\n",
       " 'bracket',\n",
       " 'brain',\n",
       " 'brainer',\n",
       " 'brake',\n",
       " 'braki',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brca',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breez',\n",
       " 'brickey',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'briefli',\n",
       " 'bright',\n",
       " 'bring',\n",
       " 'brittl',\n",
       " 'broad',\n",
       " 'broader',\n",
       " 'broadli',\n",
       " 'brochur',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'bronchiti',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brownish',\n",
       " 'bruis',\n",
       " 'bu',\n",
       " 'buck',\n",
       " 'bucket',\n",
       " 'buckl',\n",
       " 'bud',\n",
       " 'buddi',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'built',\n",
       " 'bulb',\n",
       " 'bulg',\n",
       " 'bulk',\n",
       " 'bulki',\n",
       " 'bullet',\n",
       " 'bullish',\n",
       " 'bum',\n",
       " 'bummer',\n",
       " 'bump',\n",
       " 'bumpi',\n",
       " 'bunch',\n",
       " 'bundl',\n",
       " 'bunni',\n",
       " 'burden',\n",
       " 'buri',\n",
       " 'burn',\n",
       " 'burner',\n",
       " 'burst',\n",
       " 'bush',\n",
       " 'busi',\n",
       " 'butt',\n",
       " 'buttock',\n",
       " 'button',\n",
       " 'but…',\n",
       " 'but…but',\n",
       " 'but…so',\n",
       " 'buy',\n",
       " 'bye',\n",
       " 'bypass',\n",
       " 'by…',\n",
       " 'c',\n",
       " 'ca',\n",
       " 'cabg',\n",
       " 'cafeteria',\n",
       " 'caffein',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'calcium',\n",
       " 'calcul',\n",
       " 'calendar',\n",
       " 'calibr',\n",
       " 'california',\n",
       " 'called…it',\n",
       " 'call…',\n",
       " 'calm',\n",
       " 'calypso',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campu',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'cancer…',\n",
       " 'candid',\n",
       " 'cane',\n",
       " 'cant',\n",
       " 'can…',\n",
       " 'can…i',\n",
       " 'can…if',\n",
       " 'can…it',\n",
       " 'can…w',\n",
       " 'can…you',\n",
       " 'cap',\n",
       " 'capabl',\n",
       " 'capac',\n",
       " 'capra',\n",
       " 'capsul',\n",
       " 'capsular',\n",
       " 'captain',\n",
       " 'captur',\n",
       " 'car',\n",
       " 'carbon',\n",
       " 'carcinoma',\n",
       " 'card',\n",
       " 'cardiac',\n",
       " 'cardio',\n",
       " 'cardiologist',\n",
       " 'cardiovascular',\n",
       " 'card…',\n",
       " 'care',\n",
       " 'career',\n",
       " 'caretak',\n",
       " 'carpal',\n",
       " 'carpent',\n",
       " 'carri',\n",
       " 'cart',\n",
       " 'carv',\n",
       " 'case…',\n",
       " 'cast',\n",
       " 'castrat',\n",
       " 'cat',\n",
       " 'cataract',\n",
       " 'catch',\n",
       " 'categor',\n",
       " 'categori',\n",
       " 'cater',\n",
       " 'cath',\n",
       " 'catheter',\n",
       " 'catheter…',\n",
       " 'caucasian',\n",
       " 'caught',\n",
       " 'cauter',\n",
       " 'caution',\n",
       " 'cautiou',\n",
       " 'caveat',\n",
       " 'caviti',\n",
       " 'cc',\n",
       " 'celebr',\n",
       " 'cell',\n",
       " 'cement',\n",
       " 'censu',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'centimet',\n",
       " 'central',\n",
       " 'certain',\n",
       " 'certainli',\n",
       " 'certainly…',\n",
       " 'certainti',\n",
       " 'cervic',\n",
       " 'cetera',\n",
       " 'cha',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'challeng',\n",
       " 'chamber',\n",
       " 'chance…',\n",
       " 'channel',\n",
       " 'character',\n",
       " 'characterist',\n",
       " 'charg',\n",
       " 'chart',\n",
       " 'chase',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'cheat',\n",
       " 'checkout',\n",
       " 'checkup',\n",
       " 'chef',\n",
       " 'chemic',\n",
       " 'chemo',\n",
       " 'chemotherapi',\n",
       " 'chest',\n",
       " 'chew',\n",
       " 'chf',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'chill',\n",
       " 'china',\n",
       " 'chines',\n",
       " 'chip',\n",
       " 'chiropract',\n",
       " 'chiropractor',\n",
       " 'chit',\n",
       " 'chocol',\n",
       " 'choic',\n",
       " 'cholesterol',\n",
       " 'choos',\n",
       " 'chop',\n",
       " 'chose',\n",
       " 'christ',\n",
       " 'christma',\n",
       " 'chronic',\n",
       " 'chrysler',\n",
       " 'chuckl',\n",
       " 'chunk',\n",
       " 'church',\n",
       " 'ciali',\n",
       " 'cialis…',\n",
       " 'cigar',\n",
       " 'cigarett',\n",
       " 'cipro',\n",
       " 'ciprol',\n",
       " 'circl',\n",
       " 'circul',\n",
       " 'circular',\n",
       " 'circumcis',\n",
       " 'circumst',\n",
       " 'citalopram',\n",
       " 'citi',\n",
       " 'civil',\n",
       " 'claim',\n",
       " 'clamp',\n",
       " 'clarifi',\n",
       " 'clariti',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classif',\n",
       " 'classifi',\n",
       " 'clean',\n",
       " 'cleaner',\n",
       " 'clear',\n",
       " 'clearanc',\n",
       " 'clearli',\n",
       " 'clerk',\n",
       " 'click',\n",
       " 'climax',\n",
       " 'climb',\n",
       " 'clinic',\n",
       " 'clinician',\n",
       " 'clip',\n",
       " 'clipboard',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'clot',\n",
       " 'cloth',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'clump',\n",
       " 'cluster',\n",
       " 'cm',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'coagul',\n",
       " 'coat',\n",
       " 'cobalt',\n",
       " 'cocain',\n",
       " 'cocktail',\n",
       " 'code',\n",
       " 'codein',\n",
       " 'coffe',\n",
       " 'cohort',\n",
       " 'coin',\n",
       " 'coincid',\n",
       " 'cold',\n",
       " 'colectomi',\n",
       " 'colic',\n",
       " 'coliti',\n",
       " 'collaps',\n",
       " 'collar',\n",
       " 'collater',\n",
       " 'colleagu',\n",
       " 'collect',\n",
       " 'colleg',\n",
       " 'colon',\n",
       " 'colonoscopi',\n",
       " 'color',\n",
       " 'colorado',\n",
       " 'colorect',\n",
       " 'colostomi',\n",
       " 'column',\n",
       " 'com',\n",
       " 'combat',\n",
       " 'combin',\n",
       " 'combo',\n",
       " 'comer',\n",
       " 'comfort',\n",
       " 'comment',\n",
       " 'commerci',\n",
       " 'commiss',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'commonli',\n",
       " 'commun',\n",
       " 'commut',\n",
       " 'comorbid',\n",
       " 'compani',\n",
       " 'compar',\n",
       " 'comparison',\n",
       " 'compel',\n",
       " 'compens',\n",
       " 'compet',\n",
       " 'competit',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " 'complet',\n",
       " 'complex',\n",
       " 'complic',\n",
       " 'compon',\n",
       " 'compos',\n",
       " 'comprehens',\n",
       " 'compress',\n",
       " 'compris',\n",
       " 'compromis',\n",
       " 'comput',\n",
       " 'con',\n",
       " 'conceiv',\n",
       " 'concentr',\n",
       " 'concept',\n",
       " 'conceptu',\n",
       " 'concern',\n",
       " 'conclus',\n",
       " 'concret',\n",
       " 'concur',\n",
       " 'concurr',\n",
       " 'condit',\n",
       " 'confer',\n",
       " 'confid',\n",
       " 'confin',\n",
       " 'confirm',\n",
       " 'conflict',\n",
       " 'conform',\n",
       " 'confront',\n",
       " 'confus',\n",
       " 'congest',\n",
       " 'congratul',\n",
       " 'conjunct',\n",
       " 'connect',\n",
       " 'consciou',\n",
       " 'consecut',\n",
       " 'consensu',\n",
       " 'consent',\n",
       " 'consequ',\n",
       " 'conserv',\n",
       " 'consid',\n",
       " 'consider',\n",
       " 'consist',\n",
       " 'consol',\n",
       " 'constant',\n",
       " 'constantli',\n",
       " 'constip',\n",
       " 'constraint',\n",
       " 'construct',\n",
       " 'consult',\n",
       " 'consum',\n",
       " 'contact',\n",
       " 'contain',\n",
       " 'contempl',\n",
       " 'contemporari',\n",
       " 'contend',\n",
       " 'content',\n",
       " 'context',\n",
       " 'contin',\n",
       " 'continu',\n",
       " 'contract',\n",
       " 'contraind',\n",
       " 'contrast',\n",
       " 'contribut',\n",
       " 'control',\n",
       " 'controversi',\n",
       " 'conundrum',\n",
       " 'conveni',\n",
       " 'convent',\n",
       " 'convers',\n",
       " 'convert',\n",
       " 'convinc',\n",
       " 'cook',\n",
       " 'cooki',\n",
       " 'cool',\n",
       " 'coordin',\n",
       " 'cop',\n",
       " 'copay',\n",
       " 'copd',\n",
       " 'copi',\n",
       " 'cord',\n",
       " 'core',\n",
       " 'cork',\n",
       " 'corner',\n",
       " 'coronari',\n",
       " 'correct',\n",
       " 'correctli',\n",
       " 'correl',\n",
       " 'cost',\n",
       " 'cottag',\n",
       " 'couch',\n",
       " 'cough',\n",
       " 'could…',\n",
       " 'coumadin',\n",
       " 'counsel',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'counti',\n",
       " 'countri',\n",
       " 'couple…',\n",
       " 'cours',\n",
       " 'court',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'coverag',\n",
       " 'cow',\n",
       " 'crack',\n",
       " 'cramp',\n",
       " 'crap',\n",
       " 'crappi',\n",
       " 'crash',\n",
       " 'crawl',\n",
       " 'crazi',\n",
       " 'cream',\n",
       " 'creat',\n",
       " 'credit',\n",
       " 'creep',\n",
       " 'cri',\n",
       " 'criteria',\n",
       " 'critic',\n",
       " 'croak',\n",
       " 'crohn',\n",
       " 'crop',\n",
       " 'cross',\n",
       " 'crowd',\n",
       " 'crude',\n",
       " 'crummi',\n",
       " 'crush',\n",
       " 'cryo',\n",
       " 'cryoablat',\n",
       " 'cryogen',\n",
       " 'cryosurg',\n",
       " 'cryosurgeri',\n",
       " 'cryotherapi',\n",
       " 'crystal',\n",
       " 'ct',\n",
       " 'ctr',\n",
       " 'cube',\n",
       " 'cue',\n",
       " 'cuff',\n",
       " 'cultur',\n",
       " 'cumbersom',\n",
       " 'cumul',\n",
       " 'cup',\n",
       " 'cur',\n",
       " 'curabl',\n",
       " 'curb',\n",
       " 'cure',\n",
       " 'curios',\n",
       " 'curiou',\n",
       " 'curl',\n",
       " 'current',\n",
       " 'curtain',\n",
       " 'curv',\n",
       " 'curvatur',\n",
       " 'cusp',\n",
       " 'custom',\n",
       " 'cut',\n",
       " 'cutoff',\n",
       " 'cuz',\n",
       " 'cyber',\n",
       " 'cyberknif',\n",
       " 'cycl',\n",
       " 'cylind',\n",
       " 'cyst',\n",
       " 'cystiti',\n",
       " 'cystoscopi',\n",
       " 'cytolog',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'daddi',\n",
       " 'daili',\n",
       " 'damag',\n",
       " 'damn',\n",
       " 'danger',\n",
       " 'dark',\n",
       " 'darker',\n",
       " 'darn',\n",
       " 'data',\n",
       " 'databas',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'davinci',\n",
       " 'daytim',\n",
       " 'dc',\n",
       " 'dclean',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deadli',\n",
       " 'deal',\n",
       " 'dealership',\n",
       " 'dealt',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'debat',\n",
       " 'debilit',\n",
       " 'decad',\n",
       " 'deceas',\n",
       " 'deceiv',\n",
       " 'decemb',\n",
       " 'decent',\n",
       " ...]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n] # get indices of biggest tf-idf coefficients \n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids] # get corresponding feature/value tuple based off indices\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>six</td>\n",
       "      <td>0.304083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spinal</td>\n",
       "      <td>0.241927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sphincter</td>\n",
       "      <td>0.233886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ultrasound</td>\n",
       "      <td>0.197440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rod</td>\n",
       "      <td>0.175926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flow</td>\n",
       "      <td>0.174610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>push</td>\n",
       "      <td>0.154706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>basic</td>\n",
       "      <td>0.130269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sling</td>\n",
       "      <td>0.129373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hold</td>\n",
       "      <td>0.127659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>typic</td>\n",
       "      <td>0.125817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bag</td>\n",
       "      <td>0.118035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>empti</td>\n",
       "      <td>0.111371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>injuri</td>\n",
       "      <td>0.107277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>va</td>\n",
       "      <td>0.106382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pinch</td>\n",
       "      <td>0.101766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wear</td>\n",
       "      <td>0.097519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spread</td>\n",
       "      <td>0.097448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>anxiou</td>\n",
       "      <td>0.095326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>proton</td>\n",
       "      <td>0.095326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.094833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ten</td>\n",
       "      <td>0.093960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hit</td>\n",
       "      <td>0.086724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>enough</td>\n",
       "      <td>0.086520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cath</td>\n",
       "      <td>0.086249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature     tfidf\n",
       "0          six  0.304083\n",
       "1       spinal  0.241927\n",
       "2    sphincter  0.233886\n",
       "3   ultrasound  0.197440\n",
       "4          rod  0.175926\n",
       "5         flow  0.174610\n",
       "6         push  0.154706\n",
       "7        basic  0.130269\n",
       "8        sling  0.129373\n",
       "9         hold  0.127659\n",
       "10       typic  0.125817\n",
       "11         bag  0.118035\n",
       "12       empti  0.111371\n",
       "13      injuri  0.107277\n",
       "14          va  0.106382\n",
       "15       pinch  0.101766\n",
       "16        wear  0.097519\n",
       "17      spread  0.097448\n",
       "18      anxiou  0.095326\n",
       "19      proton  0.095326\n",
       "20     perfect  0.094833\n",
       "21         ten  0.093960\n",
       "22         hit  0.086724\n",
       "23      enough  0.086520\n",
       "24        cath  0.086249"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_in_doc(tfs, features, 2, top_n=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
    "IDF(t) = log(Total number of documents / Number of documents with term t in it).\n",
    "To compute, multiply TF(t)*IDF(t) for each term. We get higher tf-idf scores for terms that are really important to certain documents (both in that they appear in few other documents, and appear a lot in a single document). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "c_vectorizer= CountVectorizer(tokenizer=tokenize, max_df = 0.7, min_df = 3, max_features=5000, stop_words = stopwords_comprehensive)\n",
    "cv = c_vectorizer.fit_transform(conversations)\n",
    "cv_feature_names = c_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "no_topics = 20\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "three seven six five yep “ va set leak posit\n",
      "Topic 1:\n",
      "typic robot six va set percent left took far five\n",
      "Topic 2:\n",
      "mm gon dr nerv three hi six robot core area\n",
      "Topic 3:\n",
      "typic robot six intermedi three incis five set basic nerv\n",
      "Topic 4:\n",
      "six three five four “ sort ten percent seven leakag\n",
      "Topic 5:\n",
      "three six “ five yep core ten seven percent four\n",
      "Topic 6:\n",
      "five percent six three ten “ four sort seven leak\n",
      "Topic 7:\n",
      "six three “ seven grade va yep ten leakag issu\n",
      "Topic 8:\n",
      "six percent “ three five benefit ten far incontin area\n",
      "Topic 9:\n",
      "inflat alrighti absorb mediocr melt aliv mister dozen vigor depend\n",
      "Topic 10:\n",
      "hmmm “ six ten percent seven three five benefit basic\n",
      "Topic 11:\n",
      "“ three six leakag five inform far took ten news\n",
      "Topic 12:\n",
      "six three ten “ percent yep five seven area eight\n",
      "Topic 13:\n",
      "six ten percent “ three seven grade five basic four\n",
      "Topic 14:\n",
      "six percent three ten five oper “ seven far sort\n",
      "Topic 15:\n",
      "three six seven nerv exactli “ basic yep far area\n",
      "Topic 16:\n",
      "three six “ five issu sort percent yep far tissu\n",
      "Topic 17:\n",
      "“ six understand three issu five va ten percent second\n",
      "Topic 18:\n",
      "six percent oncologist five three meet benefit ten dysfunct seven\n",
      "Topic 19:\n",
      "six three seven percent five “ intermedi base four core\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "display_topics(lda, cv_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk through our process of cleaning the data sets and combining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading necessary libararies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "dvd_original = pd.read_csv(\"data/DVD_Original.csv\")\n",
    "va_original = pd.read_csv(\"data/VA_Original.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View of the two datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Act_t1_avg</th>\n",
       "      <th>Act_t2_avg</th>\n",
       "      <th>Act_t2_avg_mc</th>\n",
       "      <th>Act_t3_avg</th>\n",
       "      <th>Act_t3_tot</th>\n",
       "      <th>Actpt1_t1</th>\n",
       "      <th>Actpt1_t2</th>\n",
       "      <th>Actpt1_t3</th>\n",
       "      <th>Actpt2_t1</th>\n",
       "      <th>...</th>\n",
       "      <th>ZSE4_sex_Ableorgasm</th>\n",
       "      <th>ZSE4_sex_Erectfreq</th>\n",
       "      <th>ZSE4_sex_Erectqual</th>\n",
       "      <th>ZSE4_sex_function</th>\n",
       "      <th>ZSE4_sex_ProbOverall</th>\n",
       "      <th>Choice3Comb</th>\n",
       "      <th>Choice2_Check</th>\n",
       "      <th>Choice3_Check</th>\n",
       "      <th>Choice3_lean_Check</th>\n",
       "      <th>Transcripts_Included</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Act_t1_avg  Act_t2_avg  Act_t2_avg_mc  Act_t3_avg  Act_t3_tot  \\\n",
       "0           0         NaN         NaN            NaN         NaN         NaN   \n",
       "1           1         NaN         NaN            NaN         NaN         NaN   \n",
       "2           2         3.0         NaN            NaN         NaN         NaN   \n",
       "\n",
       "   Actpt1_t1  Actpt1_t2  Actpt1_t3  Actpt2_t1          ...           \\\n",
       "0        NaN        NaN        NaN        NaN          ...            \n",
       "1        NaN        NaN        NaN        NaN          ...            \n",
       "2        3.0        NaN        NaN        1.0          ...            \n",
       "\n",
       "   ZSE4_sex_Ableorgasm  ZSE4_sex_Erectfreq  ZSE4_sex_Erectqual  \\\n",
       "0                  NaN                 NaN                 NaN   \n",
       "1                  NaN                 NaN                 NaN   \n",
       "2                  NaN                 NaN                 NaN   \n",
       "\n",
       "   ZSE4_sex_function  ZSE4_sex_ProbOverall  Choice3Comb  Choice2_Check  \\\n",
       "0                NaN                   NaN          NaN            NaN   \n",
       "1                NaN                   NaN          NaN            NaN   \n",
       "2                NaN                   NaN          NaN            NaN   \n",
       "\n",
       "   Choice3_Check  Choice3_lean_Check  Transcripts_Included  \n",
       "0            NaN                 NaN                     0  \n",
       "1            NaN                 NaN                     0  \n",
       "2            NaN                 NaN                     0  \n",
       "\n",
       "[3 rows x 516 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvd_original.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>MD</th>\n",
       "      <th>Ch_IL</th>\n",
       "      <th>RadOnc_apt</th>\n",
       "      <th>ActiveSurveillance</th>\n",
       "      <th>Surgery</th>\n",
       "      <th>Radiation</th>\n",
       "      <th>Brachy</th>\n",
       "      <th>Recom</th>\n",
       "      <th>...</th>\n",
       "      <th>MD_hispanic</th>\n",
       "      <th>MD_black</th>\n",
       "      <th>MD_native</th>\n",
       "      <th>MD_asian</th>\n",
       "      <th>MD_pacific</th>\n",
       "      <th>MD_raceother</th>\n",
       "      <th>MD_raceotherspecify</th>\n",
       "      <th>filter_$</th>\n",
       "      <th>As_1</th>\n",
       "      <th>Ch3_AS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A003</td>\n",
       "      <td>AMD010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A004</td>\n",
       "      <td>AMD012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A014</td>\n",
       "      <td>AMD010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    ID      MD  Ch_IL  RadOnc_apt  ActiveSurveillance  Surgery  \\\n",
       "0           0  A003  AMD010    2.0           0                  -2        0   \n",
       "1           1  A004  AMD012    2.0           1                  -1        0   \n",
       "2           2  A014  AMD010    1.0           1                   1        0   \n",
       "\n",
       "   Radiation  Brachy  Recom   ...    MD_hispanic  MD_black  MD_native  \\\n",
       "0          0     NaN     -1   ...            0.0       0.0        0.0   \n",
       "1          0     NaN     -1   ...            0.0       0.0        0.0   \n",
       "2         -2     NaN      1   ...            0.0       0.0        0.0   \n",
       "\n",
       "   MD_asian  MD_pacific  MD_raceother  MD_raceotherspecify  filter_$  As_1  \\\n",
       "0       0.0         0.0           0.0                  NaN       0.0   0.0   \n",
       "1       0.0         0.0           0.0                  NaN       0.0   0.0   \n",
       "2       0.0         0.0           0.0                  NaN       1.0   1.0   \n",
       "\n",
       "   Ch3_AS  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "\n",
       "[3 rows x 345 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_original.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Variable Name Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables under this section are shared between the two datasets and only need a variable name change to match because the responses to these variables are coded the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Maps variable names of one dataset to the other\n",
    "    \n",
    "    input: dataset\n",
    "    output: dataset with new matching variable names\n",
    "\"\"\"\n",
    "\n",
    "def map_var_names(df, var_map):\n",
    "    df_copy = df.copy()\n",
    "    df_changed_names = df_copy.rename(index=str, columns=var_map)\n",
    "    return df_changed_names\n",
    "\n",
    "# NOTE: we make a copy of df to preserve the integrity of the original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section matches up the patient demographic variables between the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps DVD demo. var names to var names in VA\n",
    "demo_map = {\n",
    "    'demo_ID': 'ID', 'demo_age': 'age', 'demo_education': 'education', 'demo_race_arabme': 'arabme',\n",
    "    'demo_race_hispanic': 'hispanic', 'demo_race_white': 'white', 'demo_race_black': 'black',\n",
    "    'demo_race_native': 'native', 'demo_race_asian': 'asian', 'demo_race_pacific': 'pacific',\n",
    "    'demo_race_other': 'raceother', 'demo_marry': 'marry'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physician Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section matches up the physician interaction variables between the two datasets. For example, the answer to the question, \"My physician asked for my opinion about what type of treatment would be best for me\" (Urosat10 / Opinion3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps DVD phys.interaction var names to var names in VA\n",
    "phys_map = {\n",
    "    'Urosat10': 'Opinion3', 'Urosat2_rev': 'Ask3', 'Urofeel3_t3': 'Info3',\n",
    "    'Urofeel3_t3': 'Explain3', 'UroApt_partdec': 'Involve3', 'Urosat1': 'Satis3',\n",
    "    'Dec3_best': 'Clear3', 'Urosat7': 'mdrespme', 'Urofeel6_t3': 'irespmd'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patients were administered comprehension questions to ensure they had studied the background knowledge of prostate cancer, so they could make informed decisions when choosing treatment. This section matches up the patients' answers to these comprehension questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps DVD knowledge var names to var names in VA\n",
    "know_map = {\n",
    "    'Know2_Dienot2': 'Dienot2', 'Know2_Wait2': 'Wait2', 'Know2_Sured2': 'Sured2',\n",
    "    'Know2_Raded2': 'Raded2', 'Know2_Wwed2': 'Wwed2', 'Know2_Surpee2': 'Surpee2',\n",
    "    'Know2_Radpee2': 'Radpee2', 'Know2_Wwpee2': 'Wwpee2'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anxiety Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patients were asked questions concerning how anxious thinking about cancer made them. This section matches up the variable names for the answers to these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps DVD anxiety var names to var names in VA\n",
    "anx_map = {\n",
    "    'Anx11': 'Anx11', 'Anx12': 'Anx51', 'Anx13': 'Anx61',\n",
    "    'Anx14': 'Anx71', 'Anx15': 'Anx91', 'Anx16': 'Anx111',\n",
    "    'Anx21': 'Anx12', 'Anx22': 'Anx52', 'Anx23': 'Anx62',\n",
    "    'Anx24': 'Anx72', 'Anx25': 'Anx92', 'Anx26': 'Anx112',\n",
    "    'Anx31': 'Anx13', 'Anx32': 'Anx53', 'Anx33': 'Anx63',\n",
    "    'Anx34': 'Anx73', 'Anx35': 'Anx93', 'Anx36': 'Anx113'\n",
    "}"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MD Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section matches up demographic variables on doctors that are present in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps misc. DVD var names to var names in VA\n",
    "md_demo_map = {\n",
    "    'MD1_type': 'MD_type', 'MD1_age': 'MD_gender'\n",
    "    'MD1_gender': 'MD_gender', 'MD1_race': 'MD_race'\n",
    "    'MD1_graduate': 'MD_yrgrad', 'MD1_spec': 'MD_specialty'\n",
    "    'MD1_weeklyPT': 'MD_number_pts_wk', 'MD1_percentcare':'MD_percentpts'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section matches up miscellaneous variables that are present in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps misc. DVD var names to var names in VA\n",
    "misc_map = {\n",
    "    'DA2_DA_use_dichot': 'Timeda2', \n",
    "    'Cancer_Gleason': 'gleason', 'Cancer_psa': 'psa1'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables under this section need more processing to match. Either they are coded differently, or we want to represent the data differently. As a result, the code for this processing is specific to the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Diagnosis Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section deals with the variables concerning the patients' preferences for cancer treatment prior to diagnosis. In the DVD dataset, this is coded as a single variable with six different classes. In the VA dataset, each treatment is coded as its own variable with a binary classification. We will match DVD to VA by separating each treatment option into a binary variable.\n",
    "\n",
    "Additional Note: The VA dataset has more explicitly stated treatment options, while the DVD dataset groups some of these treatments into the \"other\" category. For cohesion, we take the treatments in VA that are not explicitly stated in DVD and combine them with VA's \"other\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper funtion for conversion\n",
    "def check_matching(value, target):\n",
    "    if(value == target):\n",
    "        return 1\n",
    "    elif np.isnan(value):\n",
    "        return np.nan\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Creates dataframe where the extra VA variables are stored in \"TXother2\" col\n",
    "    \n",
    "    input: VA dataset\n",
    "    output: VA dataset with variable that groups \"other\" variables\n",
    "\"\"\"\n",
    "\n",
    "def va_other_grouping(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    temp = []\n",
    "    for i in range(len(df.index)):\n",
    "        if df_copy['Txd2'][i]==1 or df_copy['Txf2'][i]==1 or df_copy['Txg2'][i]==1:\n",
    "            temp.append(1)\n",
    "        elif np.isnan(df_copy['Txd2'][i]) and np.isnan(df_copy['Txf2'][i]) and np.isnan(df_copy['Txg2'][i]):\n",
    "            temp.append(np.nan)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    \n",
    "    df_copy['Txother2'] = np.asarray(temp)\n",
    "    return df_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also want to combine the \"Not sure\" and \"Other\" classes of DVD's variable. However, doing this may change DVD's meaning of \"Other\". Our rationale for doing this is that a \"Not Sure\" option was not included in VA, so \"Not Sure\" may already be contained within \"Other\" for VA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "    Combines \"Not Sure\" and \"Other\" options of DVD - only returns column\n",
    "    \n",
    "    input: DVD dataset\n",
    "    output: Series representing TxChoice2_orig if \"Not Sure\" and \"Other\" \n",
    "            options were combined\n",
    "\"\"\"\n",
    "\n",
    "def dvd_other_grouping(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    treat_col = df['TxChoice2_orig'].map(lambda x: 5 if (x == 5 or x == 6) \n",
    "                                         else x) \n",
    "    \n",
    "    return treat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "    Creates binary variables from DVD's TxChoice2_orig variables\n",
    "    \n",
    "    input: DVD dataset, TxChoice2_orig after running dvd_other_grouping\n",
    "    output: DVD dataset with TxChoice2_orig split into binary variables\n",
    "\"\"\"\n",
    "\n",
    "def pre_decision(df, txorig):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # matches VA variable with DVD treatment #\n",
    "    pre_dec_map = {\n",
    "        'Txa2': 2, 'Txb2': 3, 'Txc2': 4, 'Txe2': 1, 'Txother2': 5\n",
    "    }\n",
    "    \n",
    "    for key, value in pre_dec_map.items():\n",
    "        df_copy[key] = list(map(lambda x: (check_matching(x, value)), \n",
    "                               txorig))\n",
    "        \n",
    "    return df_copy    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key for shared Tx columns: <br />\n",
    "* Txa2: surgery <br />\n",
    "* Txb2: external beam radiation <br />\n",
    "* Txc2: brachytherapy <br />\n",
    "* Txe2: active surveillance <br />\n",
    "* Txother2: other\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section deals with the patients' treatment preference after consulting their physician. Both the VA and DVD datasets have fields for chosen treatment and the treatment the patient is leaning towards (if patient is unsure of choice). We will combine these two fields into a \"treatment preference\" variable.\n",
    "\n",
    "In addition, because the main goal of this analysis is to determine the conditions under which active surveillance is chosen, we will create a binary variable for active surveillance. This may help with analysis and eventual predictive machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "    Combines treatment columns into one preferred treatment column\n",
    "    \n",
    "    input: dataframe, which dataset (\"va\" or \"dvd\")\n",
    "    output: dataframe with treatment choice and treatment lean combined\n",
    "\"\"\"\n",
    "\n",
    "def combined_treatment(df, dataset):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # tuple for variable names depending on which dataset\n",
    "    tx = ('TxChoice3_decided', 'TxChoice3_lean') if dataset=='dvd' else ('Tx3', 'Txlean3')\n",
    "    \n",
    "    # combines columns\n",
    "    pref_treatment = []\n",
    "    for i in range(len(df.index)):\n",
    "        pref_treatment.append(df[tx[0]][i] if np.isnan(df[tx[1]][i]) \n",
    "                                                         else df[tx[1]][i])\n",
    "    \n",
    "    df_copy['pref_treatment'] = np.asarray(pref_treatment)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick evidence that the two columns were combined correctly by showing that null values in both fields carry over to the combined field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x182d9598e48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x182d9521518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(combined_treatment(va_original, 'va')[['Tx3', 'Txlean3', 'pref_treatment']].notna(), yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the variables for treatment decision are coded differently, they have to be converted to match. The method of this conversion will be similar to the conversion used in the \"Pre-Diagnosis Decision\" section.\n",
    "\n",
    "Shared Coding:  <br />\n",
    "1. active surveillance\n",
    "2. surgery\n",
    "3. external beam radiation\n",
    "4. brachytherapy\n",
    "5. other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map for converting each dataset to shared coding above\n",
    "va_pref_mapping = {\n",
    "    5:1, 1:2, 2:3, 3:4, 4:5, 6:5, 7:5\n",
    "}\n",
    "\n",
    "dvd_pref_mapping = {\n",
    "    1:1, 2:2, 3:3, 4:4, 5:5, 6:5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for shared coding of treatments\n",
    "def coding_helper(x, mapping):\n",
    "    if x in mapping:\n",
    "        return mapping[x]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "    Maps treatment variable to shared coding\n",
    "    \n",
    "    input: dataframe (result of combined_treatment), which dataset (\"va\" or \"dvd\")\n",
    "    output: dataframe with pref_treatment as shared coding\n",
    "\"\"\"\n",
    "\n",
    "def code_treatment(df, dataset):\n",
    "    # chooses dictionary based on dataset\n",
    "    if dataset == 'va':\n",
    "        mapping = va_pref_mapping\n",
    "    else:\n",
    "        mapping = dvd_pref_mapping\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    df_copy['pref_treatment'] = list(map((lambda x: coding_helper(x, mapping)), \n",
    "                                         df_copy['pref_treatment']))\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next function will create a binary variable for whether the patient chose active surveillance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for below\n",
    "def active_helper(x):\n",
    "    if x == 1:\n",
    "        return 1\n",
    "    elif math.isnan(x):\n",
    "        return x\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "    Creates active surveillance var\n",
    "    \n",
    "    input: dataframe (result of code_treatment)\n",
    "    output: dataframe with active surveillance var\n",
    "\"\"\"\n",
    "\n",
    "def active_var(df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['active_surv'] = list(map(active_helper, df_copy['pref_treatment']))\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Combines functions in this section into one \"treatment decision\" function\n",
    "    \n",
    "    input: dataframe, dataset (\"va\" or \"dvd\")\n",
    "    output: dataframe with pref_treatment var and active_surv var\n",
    "\"\"\"\n",
    "\n",
    "def treatment_decision(df, dataset):\n",
    "    df_copy = df.copy()\n",
    "    combined_df = combined_treatment(df_copy, dataset)\n",
    "    coded_df = code_treatment(combined_df, dataset)\n",
    "    active_df = active_var(coded_df)\n",
    "    return active_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision vs. Treatment Received"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the two datasets, there's a variable that keeps track of whether the treatment the patient chose matched the treatment they ultimately received. This section will match the variables with the same coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision3_vs_received(df_dvd, df_va):\n",
    "    lst = []\n",
    "    for i in range(len(df_dvd)):\n",
    "        if (pd.isnull(df_dvd.TxChoice3_decided[i]) == False) and (df_dvd.TxChoice3_decided[i] == df_dvd.TxGot_pt_orig[i]):\n",
    "            lst.append(1)\n",
    "        else:\n",
    "            lst.append(0)\n",
    "    df_dvd_new = df_dvd.copy()\n",
    "    df_dvd_new['decision3_vs_received'] = lst\n",
    "    column_name = {'TxgotTx3cc': 'decision3_vs_received'}\n",
    "    df_va_new = df_va.rename(index=str, columns = column_name)\n",
    "    return df_dvd_new, df_va_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will finally merge the two datasets according to the following steps:\n",
    "1. Run each dataset through their processing functions written above\n",
    "2. Find shared variables\n",
    "3. For the variables unique to each dataset, mark with a prefix (VA_ or DVD_)\n",
    "4. Concatenate the two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to find the variable names shared by the two datasets prior to processing because these variable names may interfere when we find the shared variables after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anx11',\n",
       " 'Anx12',\n",
       " 'Anx13',\n",
       " 'Anx21',\n",
       " 'Anx22',\n",
       " 'Anx23',\n",
       " 'Anx31',\n",
       " 'Anx32',\n",
       " 'Anx33',\n",
       " 'Anx41',\n",
       " 'Anx42',\n",
       " 'Anx43',\n",
       " 'Unnamed: 0',\n",
       " 'filter_$'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(va_original.columns) & set(dvd_original.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-processed shared variables consist of anxiety question variables for each of the datasets. These variables don't necessarily correspond to the same question between the datasets. However, looking at the mapping for the anxiety question section above, we see that most of the pre-processed shared variables have been mapped to the correct corresponding question. The variables that remain are: <br />\n",
    "\n",
    "Anx41, Anx42, Anx43, Unnamed: 0, filter_$ <br />\n",
    "\n",
    "When constructing the pool of shared variables, these variables will be taken out and given prefixes denoting their respective studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Takes out the \"faux\" shared variables\n",
    "    \n",
    "    input: set of shared variables\n",
    "    output: set of shared variables without variables above\n",
    "\"\"\"\n",
    "\n",
    "def filter_set(shared_set):\n",
    "    shared_set_copy = shared_set.copy()\n",
    "    \n",
    "    fake_vars = ['Anx41', 'Anx42', 'Anx43', 'Unnamed: 0', 'filter_$']\n",
    "    for var in fake_vars:\n",
    "        shared_set_copy.discard(var)\n",
    "    return shared_set_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're at it, let's make a function that adds prefixes to the unique variables of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for prefix adder below\n",
    "def prefix_helper(x, prefix, shared_vars):\n",
    "    if x in shared_vars:\n",
    "        return x\n",
    "    else: \n",
    "        return prefix + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Adds prefixes to the unique variables in each dataset\n",
    "    \n",
    "    input: dataframe, dataset (\"va\" or \"dvd\"), set of shared vars\n",
    "    output: dataframe with the unique variables prefixed\n",
    "\"\"\"\n",
    "\n",
    "def add_prefix(df, dataset, shared_vars):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    prefix = ''\n",
    "    if dataset == 'va':\n",
    "        prefix = 'VA_'\n",
    "    if dataset == 'dvd':\n",
    "        prefix = 'DVD_'\n",
    "        \n",
    "    df_copy.columns = list(map(lambda x: prefix_helper(x, prefix, shared_vars),\n",
    "                              df.columns))\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function will run each dataset through their processing functions as defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Processes datasets to get ready for merging\n",
    "    \n",
    "    input: both original dataframes\n",
    "    output: datasets ready to be merged\n",
    "\"\"\"\n",
    "\n",
    "def process_data(df1, df2):\n",
    "    va = df1.copy()\n",
    "    dvd = df2.copy()\n",
    "    \n",
    "    # dvd simple name changes\n",
    "    demo_dvd = map_var_names(dvd, demo_map)\n",
    "    phys_dvd = map_var_names(demo_dvd, phys_map)\n",
    "    know_dvd = map_var_names(phys_dvd, know_map)\n",
    "    anx_dvd = map_var_names(know_dvd, anx_map)\n",
    "    misc_dvd = map_var_names(anx_dvd, misc_map)\n",
    "    \n",
    "    # pre-diagnosis decision processing\n",
    "    pre_va = va_other_grouping(va)\n",
    "    pre_dvd = pre_decision(misc_dvd, dvd_other_grouping(misc_dvd))\n",
    "    \n",
    "    # treatment decision processing\n",
    "    treat_va = treatment_decision(pre_va, 'va')\n",
    "    treat_dvd = treatment_decision(pre_dvd, 'dvd')\n",
    "    \n",
    "    # treatment decision vs treatment received\n",
    "    final_dvd, final_va = decision3_vs_received(treat_dvd, treat_va)\n",
    "    \n",
    "    return final_va, final_dvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apologies if this processing function seems convoluted because of the chain of function calls. However, I think having each step of processing in its own function will make it easier to add new steps of processing down the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a function that finds the shared variables and makes the distinction between shared and unique variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Finds set of shared variables and marks shared and distinct variables \n",
    "    in each dataframe\n",
    "    \n",
    "    input: processed va, processed dvd (result of process_data)\n",
    "    output: two ready to merge dataframes\n",
    "\"\"\"\n",
    "def process_shared(df1, df2):\n",
    "    va = df1.copy()\n",
    "    dvd = df2.copy()\n",
    "    \n",
    "    # finds the shared variables between the datasets\n",
    "    shared_vars = set(va) & set(dvd)\n",
    "    filtered_vars = filter_set(shared_vars)\n",
    "    \n",
    "    # marks dataframes with prefixes for unique variables\n",
    "    final_va = add_prefix(va, 'va', filtered_vars)\n",
    "    final_dvd = add_prefix(dvd, 'dvd', filtered_vars)\n",
    "    \n",
    "    return final_va, final_dvd, filtered_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will merge the two processed datasets into a beautiful, singular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Takes two original datasets and returns merged dataset\n",
    "    \n",
    "    input: original va, original dvd\n",
    "    output: merged dataframe\n",
    "\"\"\"\n",
    "\n",
    "def merge(va_original, dvd_original):\n",
    "    # runs original dataframes through above processing functions\n",
    "    processed_va, processed_dvd = process_data(va_original, dvd_original)\n",
    "    tagged_va, tagged_dvd, filtered_vars = process_shared(processed_va, processed_dvd)\n",
    "    \n",
    "    merged_df = pd.concat([tagged_va, tagged_dvd])\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moment of Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anx11</th>\n",
       "      <th>Anx111</th>\n",
       "      <th>Anx112</th>\n",
       "      <th>Anx113</th>\n",
       "      <th>Anx12</th>\n",
       "      <th>Anx13</th>\n",
       "      <th>Anx51</th>\n",
       "      <th>Anx52</th>\n",
       "      <th>Anx53</th>\n",
       "      <th>Anx61</th>\n",
       "      <th>...</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>irespmd</th>\n",
       "      <th>marry</th>\n",
       "      <th>mdrespme</th>\n",
       "      <th>native</th>\n",
       "      <th>pacific</th>\n",
       "      <th>pref_treatment</th>\n",
       "      <th>psa1</th>\n",
       "      <th>raceother</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Anx11  Anx111  Anx112  Anx113  Anx12  Anx13  Anx51  Anx52  Anx53  Anx61  \\\n",
       "0    1.0     1.0     0.0     2.0    3.0    2.0    1.0    1.0    1.0    1.0   \n",
       "1    0.0     0.0     2.0     2.0    2.0    1.0    1.0    2.0    2.0    1.0   \n",
       "2    2.0     3.0     2.0     3.0    2.0    2.0    1.0    2.0    3.0    2.0   \n",
       "3    0.0     0.0     0.0     1.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4    2.0     2.0     2.0     2.0    3.0    2.0    2.0    2.0    1.0    0.0   \n",
       "\n",
       "   ...    hispanic  irespmd  marry  mdrespme  native  pacific  pref_treatment  \\\n",
       "0  ...         0.0      4.0    4.0       4.0     0.0      0.0             2.0   \n",
       "1  ...         0.0      5.0    3.0       5.0     0.0      0.0             2.0   \n",
       "2  ...         0.0      4.0    3.0       4.0     0.0      0.0             2.0   \n",
       "3  ...         0.0      4.0    1.0       4.0     0.0      0.0             2.0   \n",
       "4  ...         0.0      4.0    5.0       3.0     0.0      0.0             1.0   \n",
       "\n",
       "   psa1  raceother  white  \n",
       "0  4.67        NaN    1.0  \n",
       "1  5.66        NaN    1.0  \n",
       "2  4.10        NaN    1.0  \n",
       "3  4.74        NaN    1.0  \n",
       "4  5.53        NaN    1.0  \n",
       "\n",
       "[5 rows x 815 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge(va_original, dvd_original).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um. So it compiled. Now we have to run some tests to see if the integrity of each dataset was preserved through the merge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
